{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca209422",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dhruvin/Downloads/SoC_Battle-Of-The-Bots/venv/lib/python3.10/site-packages/pygame/pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from collections import deque\n",
    "import pygame\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eddc73b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DQN model which takes in the state as an input and outputs predicted q values for every possible action\n",
    "class DQN(torch.nn.Module):\n",
    "    def __init__(self, state_space, action_space):\n",
    "        super().__init__()\n",
    "        # Add your architecture parameters here\n",
    "        # You can use nn.Functional\n",
    "        # Remember that the input is of size batch_size x state_space\n",
    "        # and the output is of size batch_size x action_space (ulta ho sakta hai dekh lo)\n",
    "        # TODO: Add code here\n",
    "        self.fc1 = nn.Linear(state_space, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.out = nn.Linear(128, action_space)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # TODO: Complete based on your implementation\n",
    "        x = self.fc1(input)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37adca73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# While training neural networks, we split the data into batches.\n",
    "# To improve the training, we need to remove the \"correlation\" between game states\n",
    "# The buffer starts storing states and once it reaches maximum capacity, it replaces\n",
    "# states at random which reduces the correlation.\n",
    "class ExperienceBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "    \n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        self.buffer.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        batch = random.sample(self.buffer, batch_size)\n",
    "        states, actions, rewards, next_states, dones = zip(*batch)\n",
    "        return states, actions, rewards, next_states, dones\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe4d26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0, Total Reward: 29.0\n",
      "Episode 1, Total Reward: 18.0\n",
      "Episode 2, Total Reward: 13.0\n",
      "Episode 3, Total Reward: 14.0\n",
      "Episode 4, Total Reward: 13.0\n",
      "Episode 5, Total Reward: 12.0\n",
      "Episode 6, Total Reward: 17.0\n",
      "Episode 7, Total Reward: 56.0\n",
      "Episode 8, Total Reward: 16.0\n",
      "Episode 9, Total Reward: 17.0\n",
      "Episode 10, Total Reward: 16.0\n",
      "Episode 11, Total Reward: 16.0\n",
      "Episode 12, Total Reward: 16.0\n",
      "Episode 13, Total Reward: 20.0\n",
      "Episode 14, Total Reward: 26.0\n",
      "Episode 15, Total Reward: 13.0\n",
      "Episode 16, Total Reward: 17.0\n",
      "Episode 17, Total Reward: 46.0\n",
      "Episode 18, Total Reward: 22.0\n",
      "Episode 19, Total Reward: 24.0\n",
      "Episode 20, Total Reward: 11.0\n",
      "Episode 21, Total Reward: 41.0\n",
      "Episode 22, Total Reward: 14.0\n",
      "Episode 23, Total Reward: 42.0\n",
      "Episode 24, Total Reward: 21.0\n",
      "Episode 25, Total Reward: 19.0\n",
      "Episode 26, Total Reward: 13.0\n",
      "Episode 27, Total Reward: 18.0\n",
      "Episode 28, Total Reward: 16.0\n",
      "Episode 29, Total Reward: 22.0\n",
      "Episode 30, Total Reward: 35.0\n",
      "Episode 31, Total Reward: 22.0\n",
      "Episode 32, Total Reward: 16.0\n",
      "Episode 33, Total Reward: 29.0\n",
      "Episode 34, Total Reward: 21.0\n",
      "Episode 35, Total Reward: 14.0\n",
      "Episode 36, Total Reward: 18.0\n",
      "Episode 37, Total Reward: 80.0\n",
      "Episode 38, Total Reward: 16.0\n",
      "Episode 39, Total Reward: 37.0\n",
      "Episode 40, Total Reward: 26.0\n",
      "Episode 41, Total Reward: 13.0\n",
      "Episode 42, Total Reward: 63.0\n",
      "Episode 43, Total Reward: 18.0\n",
      "Episode 44, Total Reward: 20.0\n",
      "Episode 45, Total Reward: 56.0\n",
      "Episode 46, Total Reward: 18.0\n",
      "Episode 47, Total Reward: 25.0\n",
      "Episode 48, Total Reward: 18.0\n",
      "Episode 49, Total Reward: 38.0\n",
      "Episode 50, Total Reward: 59.0\n",
      "Episode 51, Total Reward: 29.0\n",
      "Episode 52, Total Reward: 34.0\n",
      "Episode 53, Total Reward: 12.0\n",
      "Episode 54, Total Reward: 32.0\n",
      "Episode 55, Total Reward: 11.0\n",
      "Episode 56, Total Reward: 16.0\n",
      "Episode 57, Total Reward: 38.0\n",
      "Episode 58, Total Reward: 22.0\n",
      "Episode 59, Total Reward: 19.0\n",
      "Episode 60, Total Reward: 39.0\n",
      "Episode 61, Total Reward: 16.0\n",
      "Episode 62, Total Reward: 17.0\n",
      "Episode 63, Total Reward: 30.0\n",
      "Episode 64, Total Reward: 28.0\n",
      "Episode 65, Total Reward: 36.0\n",
      "Episode 66, Total Reward: 20.0\n",
      "Episode 67, Total Reward: 28.0\n",
      "Episode 68, Total Reward: 32.0\n",
      "Episode 69, Total Reward: 12.0\n",
      "Episode 70, Total Reward: 26.0\n",
      "Episode 71, Total Reward: 11.0\n",
      "Episode 72, Total Reward: 10.0\n",
      "Episode 73, Total Reward: 33.0\n",
      "Episode 74, Total Reward: 17.0\n",
      "Episode 75, Total Reward: 35.0\n",
      "Episode 76, Total Reward: 33.0\n",
      "Episode 77, Total Reward: 45.0\n",
      "Episode 78, Total Reward: 14.0\n",
      "Episode 79, Total Reward: 28.0\n",
      "Episode 80, Total Reward: 10.0\n",
      "Episode 81, Total Reward: 27.0\n",
      "Episode 82, Total Reward: 16.0\n",
      "Episode 83, Total Reward: 20.0\n",
      "Episode 84, Total Reward: 11.0\n",
      "Episode 85, Total Reward: 9.0\n",
      "Episode 86, Total Reward: 16.0\n",
      "Episode 87, Total Reward: 26.0\n",
      "Episode 88, Total Reward: 11.0\n",
      "Episode 89, Total Reward: 9.0\n",
      "Episode 90, Total Reward: 15.0\n",
      "Episode 91, Total Reward: 67.0\n",
      "Episode 92, Total Reward: 23.0\n",
      "Episode 93, Total Reward: 27.0\n",
      "Episode 94, Total Reward: 12.0\n",
      "Episode 95, Total Reward: 11.0\n",
      "Episode 96, Total Reward: 14.0\n",
      "Episode 97, Total Reward: 9.0\n",
      "Episode 98, Total Reward: 22.0\n",
      "Episode 99, Total Reward: 20.0\n",
      "Episode 100, Total Reward: 77.0\n",
      "Episode 101, Total Reward: 23.0\n",
      "Episode 102, Total Reward: 22.0\n",
      "Episode 103, Total Reward: 17.0\n",
      "Episode 104, Total Reward: 17.0\n",
      "Episode 105, Total Reward: 14.0\n",
      "Episode 106, Total Reward: 41.0\n",
      "Episode 107, Total Reward: 13.0\n",
      "Episode 108, Total Reward: 35.0\n",
      "Episode 109, Total Reward: 69.0\n",
      "Episode 110, Total Reward: 20.0\n",
      "Episode 111, Total Reward: 46.0\n",
      "Episode 112, Total Reward: 16.0\n",
      "Episode 113, Total Reward: 44.0\n",
      "Episode 114, Total Reward: 49.0\n",
      "Episode 115, Total Reward: 25.0\n",
      "Episode 116, Total Reward: 21.0\n",
      "Episode 117, Total Reward: 36.0\n",
      "Episode 118, Total Reward: 29.0\n",
      "Episode 119, Total Reward: 25.0\n",
      "Episode 120, Total Reward: 23.0\n",
      "Episode 121, Total Reward: 32.0\n",
      "Episode 122, Total Reward: 20.0\n",
      "Episode 123, Total Reward: 40.0\n",
      "Episode 124, Total Reward: 12.0\n",
      "Episode 125, Total Reward: 35.0\n",
      "Episode 126, Total Reward: 23.0\n",
      "Episode 127, Total Reward: 22.0\n",
      "Episode 128, Total Reward: 62.0\n",
      "Episode 129, Total Reward: 14.0\n",
      "Episode 130, Total Reward: 39.0\n",
      "Episode 131, Total Reward: 17.0\n",
      "Episode 132, Total Reward: 35.0\n",
      "Episode 133, Total Reward: 12.0\n",
      "Episode 134, Total Reward: 38.0\n",
      "Episode 135, Total Reward: 12.0\n",
      "Episode 136, Total Reward: 22.0\n",
      "Episode 137, Total Reward: 15.0\n",
      "Episode 138, Total Reward: 39.0\n",
      "Episode 139, Total Reward: 12.0\n",
      "Episode 140, Total Reward: 21.0\n",
      "Episode 141, Total Reward: 46.0\n",
      "Episode 142, Total Reward: 46.0\n",
      "Episode 143, Total Reward: 32.0\n",
      "Episode 144, Total Reward: 16.0\n",
      "Episode 145, Total Reward: 36.0\n",
      "Episode 146, Total Reward: 23.0\n",
      "Episode 147, Total Reward: 29.0\n",
      "Episode 148, Total Reward: 30.0\n",
      "Episode 149, Total Reward: 10.0\n",
      "Episode 150, Total Reward: 14.0\n",
      "Episode 151, Total Reward: 15.0\n",
      "Episode 152, Total Reward: 14.0\n",
      "Episode 153, Total Reward: 20.0\n",
      "Episode 154, Total Reward: 34.0\n",
      "Episode 155, Total Reward: 20.0\n",
      "Episode 156, Total Reward: 41.0\n",
      "Episode 157, Total Reward: 22.0\n",
      "Episode 158, Total Reward: 36.0\n",
      "Episode 159, Total Reward: 19.0\n",
      "Episode 160, Total Reward: 24.0\n",
      "Episode 161, Total Reward: 51.0\n",
      "Episode 162, Total Reward: 41.0\n",
      "Episode 163, Total Reward: 14.0\n",
      "Episode 164, Total Reward: 27.0\n",
      "Episode 165, Total Reward: 32.0\n",
      "Episode 166, Total Reward: 13.0\n",
      "Episode 167, Total Reward: 19.0\n",
      "Episode 168, Total Reward: 39.0\n",
      "Episode 169, Total Reward: 9.0\n",
      "Episode 170, Total Reward: 20.0\n",
      "Episode 171, Total Reward: 51.0\n",
      "Episode 172, Total Reward: 20.0\n",
      "Episode 173, Total Reward: 26.0\n",
      "Episode 174, Total Reward: 11.0\n",
      "Episode 175, Total Reward: 43.0\n",
      "Episode 176, Total Reward: 17.0\n",
      "Episode 177, Total Reward: 47.0\n",
      "Episode 178, Total Reward: 118.0\n",
      "Episode 179, Total Reward: 24.0\n",
      "Episode 180, Total Reward: 14.0\n",
      "Episode 181, Total Reward: 11.0\n",
      "Episode 182, Total Reward: 19.0\n",
      "Episode 183, Total Reward: 23.0\n",
      "Episode 184, Total Reward: 53.0\n",
      "Episode 185, Total Reward: 22.0\n",
      "Episode 186, Total Reward: 33.0\n",
      "Episode 187, Total Reward: 40.0\n",
      "Episode 188, Total Reward: 13.0\n",
      "Episode 189, Total Reward: 32.0\n",
      "Episode 190, Total Reward: 19.0\n",
      "Episode 191, Total Reward: 37.0\n",
      "Episode 192, Total Reward: 23.0\n",
      "Episode 193, Total Reward: 51.0\n",
      "Episode 194, Total Reward: 62.0\n",
      "Episode 195, Total Reward: 39.0\n",
      "Episode 196, Total Reward: 27.0\n",
      "Episode 197, Total Reward: 27.0\n",
      "Episode 198, Total Reward: 32.0\n",
      "Episode 199, Total Reward: 13.0\n",
      "Episode 200, Total Reward: 41.0\n",
      "Episode 201, Total Reward: 24.0\n",
      "Episode 202, Total Reward: 45.0\n",
      "Episode 203, Total Reward: 18.0\n",
      "Episode 204, Total Reward: 13.0\n",
      "Episode 205, Total Reward: 39.0\n",
      "Episode 206, Total Reward: 51.0\n",
      "Episode 207, Total Reward: 12.0\n",
      "Episode 208, Total Reward: 26.0\n",
      "Episode 209, Total Reward: 16.0\n",
      "Episode 210, Total Reward: 17.0\n",
      "Episode 211, Total Reward: 29.0\n",
      "Episode 212, Total Reward: 16.0\n",
      "Episode 213, Total Reward: 14.0\n",
      "Episode 214, Total Reward: 22.0\n",
      "Episode 215, Total Reward: 28.0\n",
      "Episode 216, Total Reward: 17.0\n",
      "Episode 217, Total Reward: 31.0\n",
      "Episode 218, Total Reward: 16.0\n",
      "Episode 219, Total Reward: 37.0\n",
      "Episode 220, Total Reward: 19.0\n",
      "Episode 221, Total Reward: 8.0\n",
      "Episode 222, Total Reward: 34.0\n",
      "Episode 223, Total Reward: 49.0\n",
      "Episode 224, Total Reward: 94.0\n",
      "Episode 225, Total Reward: 11.0\n",
      "Episode 226, Total Reward: 18.0\n",
      "Episode 227, Total Reward: 39.0\n",
      "Episode 228, Total Reward: 19.0\n",
      "Episode 229, Total Reward: 26.0\n",
      "Episode 230, Total Reward: 32.0\n",
      "Episode 231, Total Reward: 68.0\n",
      "Episode 232, Total Reward: 48.0\n",
      "Episode 233, Total Reward: 14.0\n",
      "Episode 234, Total Reward: 33.0\n",
      "Episode 235, Total Reward: 40.0\n",
      "Episode 236, Total Reward: 21.0\n",
      "Episode 237, Total Reward: 11.0\n",
      "Episode 238, Total Reward: 53.0\n",
      "Episode 239, Total Reward: 16.0\n",
      "Episode 240, Total Reward: 17.0\n",
      "Episode 241, Total Reward: 27.0\n",
      "Episode 242, Total Reward: 22.0\n",
      "Episode 243, Total Reward: 25.0\n",
      "Episode 244, Total Reward: 50.0\n",
      "Episode 245, Total Reward: 29.0\n",
      "Episode 246, Total Reward: 33.0\n",
      "Episode 247, Total Reward: 110.0\n",
      "Episode 248, Total Reward: 39.0\n",
      "Episode 249, Total Reward: 25.0\n",
      "Episode 250, Total Reward: 13.0\n",
      "Episode 251, Total Reward: 28.0\n",
      "Episode 252, Total Reward: 15.0\n",
      "Episode 253, Total Reward: 43.0\n",
      "Episode 254, Total Reward: 50.0\n",
      "Episode 255, Total Reward: 24.0\n",
      "Episode 256, Total Reward: 16.0\n",
      "Episode 257, Total Reward: 27.0\n",
      "Episode 258, Total Reward: 33.0\n",
      "Episode 259, Total Reward: 70.0\n",
      "Episode 260, Total Reward: 22.0\n",
      "Episode 261, Total Reward: 60.0\n",
      "Episode 262, Total Reward: 15.0\n",
      "Episode 263, Total Reward: 20.0\n",
      "Episode 264, Total Reward: 11.0\n",
      "Episode 265, Total Reward: 15.0\n",
      "Episode 266, Total Reward: 39.0\n",
      "Episode 267, Total Reward: 34.0\n",
      "Episode 268, Total Reward: 26.0\n",
      "Episode 269, Total Reward: 24.0\n",
      "Episode 270, Total Reward: 11.0\n",
      "Episode 271, Total Reward: 24.0\n",
      "Episode 272, Total Reward: 36.0\n",
      "Episode 273, Total Reward: 27.0\n",
      "Episode 274, Total Reward: 14.0\n",
      "Episode 275, Total Reward: 12.0\n",
      "Episode 276, Total Reward: 21.0\n",
      "Episode 277, Total Reward: 54.0\n",
      "Episode 278, Total Reward: 60.0\n",
      "Episode 279, Total Reward: 27.0\n",
      "Episode 280, Total Reward: 14.0\n",
      "Episode 281, Total Reward: 12.0\n",
      "Episode 282, Total Reward: 14.0\n",
      "Episode 283, Total Reward: 14.0\n",
      "Episode 284, Total Reward: 28.0\n",
      "Episode 285, Total Reward: 19.0\n",
      "Episode 286, Total Reward: 14.0\n",
      "Episode 287, Total Reward: 18.0\n",
      "Episode 288, Total Reward: 16.0\n",
      "Episode 289, Total Reward: 13.0\n",
      "Episode 290, Total Reward: 16.0\n",
      "Episode 291, Total Reward: 38.0\n",
      "Episode 292, Total Reward: 36.0\n",
      "Episode 293, Total Reward: 13.0\n",
      "Episode 294, Total Reward: 37.0\n",
      "Episode 295, Total Reward: 27.0\n",
      "Episode 296, Total Reward: 15.0\n",
      "Episode 297, Total Reward: 11.0\n",
      "Episode 298, Total Reward: 11.0\n",
      "Episode 299, Total Reward: 55.0\n",
      "Episode 300, Total Reward: 20.0\n",
      "Episode 301, Total Reward: 27.0\n",
      "Episode 302, Total Reward: 13.0\n",
      "Episode 303, Total Reward: 18.0\n",
      "Episode 304, Total Reward: 17.0\n",
      "Episode 305, Total Reward: 13.0\n",
      "Episode 306, Total Reward: 33.0\n",
      "Episode 307, Total Reward: 20.0\n",
      "Episode 308, Total Reward: 25.0\n",
      "Episode 309, Total Reward: 13.0\n",
      "Episode 310, Total Reward: 43.0\n",
      "Episode 311, Total Reward: 14.0\n",
      "Episode 312, Total Reward: 20.0\n",
      "Episode 313, Total Reward: 20.0\n",
      "Episode 314, Total Reward: 64.0\n",
      "Episode 315, Total Reward: 11.0\n",
      "Episode 316, Total Reward: 18.0\n",
      "Episode 317, Total Reward: 11.0\n",
      "Episode 318, Total Reward: 43.0\n",
      "Episode 319, Total Reward: 37.0\n",
      "Episode 320, Total Reward: 18.0\n",
      "Episode 321, Total Reward: 27.0\n",
      "Episode 322, Total Reward: 19.0\n",
      "Episode 323, Total Reward: 33.0\n",
      "Episode 324, Total Reward: 16.0\n",
      "Episode 325, Total Reward: 75.0\n",
      "Episode 326, Total Reward: 18.0\n",
      "Episode 327, Total Reward: 26.0\n",
      "Episode 328, Total Reward: 23.0\n",
      "Episode 329, Total Reward: 84.0\n",
      "Episode 330, Total Reward: 25.0\n",
      "Episode 331, Total Reward: 20.0\n",
      "Episode 332, Total Reward: 22.0\n",
      "Episode 333, Total Reward: 28.0\n",
      "Episode 334, Total Reward: 24.0\n",
      "Episode 335, Total Reward: 14.0\n",
      "Episode 336, Total Reward: 26.0\n",
      "Episode 337, Total Reward: 14.0\n",
      "Episode 338, Total Reward: 13.0\n",
      "Episode 339, Total Reward: 49.0\n",
      "Episode 340, Total Reward: 31.0\n",
      "Episode 341, Total Reward: 21.0\n",
      "Episode 342, Total Reward: 51.0\n",
      "Episode 343, Total Reward: 14.0\n",
      "Episode 344, Total Reward: 14.0\n",
      "Episode 345, Total Reward: 16.0\n",
      "Episode 346, Total Reward: 20.0\n",
      "Episode 347, Total Reward: 33.0\n",
      "Episode 348, Total Reward: 25.0\n",
      "Episode 349, Total Reward: 48.0\n",
      "Episode 350, Total Reward: 39.0\n",
      "Episode 351, Total Reward: 20.0\n",
      "Episode 352, Total Reward: 24.0\n",
      "Episode 353, Total Reward: 11.0\n",
      "Episode 354, Total Reward: 24.0\n",
      "Episode 355, Total Reward: 27.0\n",
      "Episode 356, Total Reward: 30.0\n",
      "Episode 357, Total Reward: 72.0\n",
      "Episode 358, Total Reward: 24.0\n",
      "Episode 359, Total Reward: 23.0\n",
      "Episode 360, Total Reward: 41.0\n",
      "Episode 361, Total Reward: 11.0\n",
      "Episode 362, Total Reward: 23.0\n",
      "Episode 363, Total Reward: 53.0\n",
      "Episode 364, Total Reward: 15.0\n",
      "Episode 365, Total Reward: 48.0\n",
      "Episode 366, Total Reward: 22.0\n",
      "Episode 367, Total Reward: 31.0\n",
      "Episode 368, Total Reward: 14.0\n",
      "Episode 369, Total Reward: 13.0\n",
      "Episode 370, Total Reward: 13.0\n",
      "Episode 371, Total Reward: 14.0\n",
      "Episode 372, Total Reward: 63.0\n",
      "Episode 373, Total Reward: 37.0\n",
      "Episode 374, Total Reward: 31.0\n",
      "Episode 375, Total Reward: 36.0\n",
      "Episode 376, Total Reward: 20.0\n",
      "Episode 377, Total Reward: 30.0\n",
      "Episode 378, Total Reward: 23.0\n",
      "Episode 379, Total Reward: 21.0\n",
      "Episode 380, Total Reward: 19.0\n",
      "Episode 381, Total Reward: 41.0\n",
      "Episode 382, Total Reward: 41.0\n",
      "Episode 383, Total Reward: 40.0\n",
      "Episode 384, Total Reward: 13.0\n",
      "Episode 385, Total Reward: 61.0\n",
      "Episode 386, Total Reward: 31.0\n",
      "Episode 387, Total Reward: 56.0\n",
      "Episode 388, Total Reward: 28.0\n",
      "Episode 389, Total Reward: 33.0\n",
      "Episode 390, Total Reward: 30.0\n",
      "Episode 391, Total Reward: 15.0\n",
      "Episode 392, Total Reward: 16.0\n",
      "Episode 393, Total Reward: 18.0\n",
      "Episode 394, Total Reward: 21.0\n",
      "Episode 395, Total Reward: 37.0\n",
      "Episode 396, Total Reward: 65.0\n",
      "Episode 397, Total Reward: 24.0\n",
      "Episode 398, Total Reward: 54.0\n",
      "Episode 399, Total Reward: 11.0\n",
      "Episode 400, Total Reward: 41.0\n",
      "Episode 401, Total Reward: 23.0\n",
      "Episode 402, Total Reward: 28.0\n",
      "Episode 403, Total Reward: 13.0\n",
      "Episode 404, Total Reward: 23.0\n",
      "Episode 405, Total Reward: 19.0\n",
      "Episode 406, Total Reward: 24.0\n",
      "Episode 407, Total Reward: 33.0\n",
      "Episode 408, Total Reward: 13.0\n",
      "Episode 409, Total Reward: 63.0\n",
      "Episode 410, Total Reward: 34.0\n",
      "Episode 411, Total Reward: 21.0\n",
      "Episode 412, Total Reward: 20.0\n",
      "Episode 413, Total Reward: 20.0\n",
      "Episode 414, Total Reward: 14.0\n",
      "Episode 415, Total Reward: 21.0\n",
      "Episode 416, Total Reward: 15.0\n",
      "Episode 417, Total Reward: 15.0\n",
      "Episode 418, Total Reward: 18.0\n",
      "Episode 419, Total Reward: 41.0\n",
      "Episode 420, Total Reward: 21.0\n",
      "Episode 421, Total Reward: 12.0\n",
      "Episode 422, Total Reward: 19.0\n",
      "Episode 423, Total Reward: 26.0\n",
      "Episode 424, Total Reward: 10.0\n",
      "Episode 425, Total Reward: 15.0\n",
      "Episode 426, Total Reward: 12.0\n",
      "Episode 427, Total Reward: 13.0\n",
      "Episode 428, Total Reward: 16.0\n",
      "Episode 429, Total Reward: 17.0\n",
      "Episode 430, Total Reward: 23.0\n",
      "Episode 431, Total Reward: 12.0\n",
      "Episode 432, Total Reward: 25.0\n",
      "Episode 433, Total Reward: 17.0\n",
      "Episode 434, Total Reward: 56.0\n",
      "Episode 435, Total Reward: 13.0\n",
      "Episode 436, Total Reward: 73.0\n",
      "Episode 437, Total Reward: 15.0\n",
      "Episode 438, Total Reward: 40.0\n",
      "Episode 439, Total Reward: 23.0\n",
      "Episode 440, Total Reward: 39.0\n",
      "Episode 441, Total Reward: 11.0\n",
      "Episode 442, Total Reward: 32.0\n",
      "Episode 443, Total Reward: 14.0\n",
      "Episode 444, Total Reward: 59.0\n",
      "Episode 445, Total Reward: 20.0\n",
      "Episode 446, Total Reward: 12.0\n",
      "Episode 447, Total Reward: 15.0\n",
      "Episode 448, Total Reward: 14.0\n",
      "Episode 449, Total Reward: 21.0\n",
      "Episode 450, Total Reward: 16.0\n",
      "Episode 451, Total Reward: 13.0\n",
      "Episode 452, Total Reward: 14.0\n",
      "Episode 453, Total Reward: 16.0\n",
      "Episode 454, Total Reward: 16.0\n",
      "Episode 455, Total Reward: 34.0\n",
      "Episode 456, Total Reward: 14.0\n",
      "Episode 457, Total Reward: 18.0\n",
      "Episode 458, Total Reward: 61.0\n",
      "Episode 459, Total Reward: 16.0\n",
      "Episode 460, Total Reward: 29.0\n",
      "Episode 461, Total Reward: 14.0\n",
      "Episode 462, Total Reward: 54.0\n",
      "Episode 463, Total Reward: 18.0\n",
      "Episode 464, Total Reward: 12.0\n",
      "Episode 465, Total Reward: 16.0\n",
      "Episode 466, Total Reward: 19.0\n",
      "Episode 467, Total Reward: 26.0\n",
      "Episode 468, Total Reward: 141.0\n",
      "Episode 469, Total Reward: 22.0\n",
      "Episode 470, Total Reward: 16.0\n",
      "Episode 471, Total Reward: 11.0\n",
      "Episode 472, Total Reward: 27.0\n",
      "Episode 473, Total Reward: 13.0\n",
      "Episode 474, Total Reward: 14.0\n",
      "Episode 475, Total Reward: 17.0\n",
      "Episode 476, Total Reward: 22.0\n",
      "Episode 477, Total Reward: 23.0\n",
      "Episode 478, Total Reward: 31.0\n",
      "Episode 479, Total Reward: 18.0\n",
      "Episode 480, Total Reward: 48.0\n",
      "Episode 481, Total Reward: 34.0\n",
      "Episode 482, Total Reward: 20.0\n",
      "Episode 483, Total Reward: 41.0\n",
      "Episode 484, Total Reward: 34.0\n",
      "Episode 485, Total Reward: 72.0\n",
      "Episode 486, Total Reward: 49.0\n",
      "Episode 487, Total Reward: 14.0\n",
      "Episode 488, Total Reward: 47.0\n",
      "Episode 489, Total Reward: 12.0\n",
      "Episode 490, Total Reward: 14.0\n",
      "Episode 491, Total Reward: 33.0\n",
      "Episode 492, Total Reward: 28.0\n",
      "Episode 493, Total Reward: 26.0\n",
      "Episode 494, Total Reward: 33.0\n",
      "Episode 495, Total Reward: 12.0\n",
      "Episode 496, Total Reward: 24.0\n",
      "Episode 497, Total Reward: 38.0\n",
      "Episode 498, Total Reward: 28.0\n",
      "Episode 499, Total Reward: 20.0\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# TODO: Implement training logic for CartPole environment here\n",
    "# Remember to use the ExperienceBuffer and a target network\n",
    "# Details can be found in the book sent in the group\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "state_space = env.observation_space.shape[0]\n",
    "action_space = env.action_space.n\n",
    "policy_net = DQN(state_space, action_space)\n",
    "target_net = DQN(state_space, action_space)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "optimizer = torch.optim.Adam(policy_net.parameters(), lr = 1e-3)\n",
    "criterion = torch.nn.MSELoss()\n",
    "buffer = ExperienceBuffer(capacity=10000)\n",
    "batch_size = 64\n",
    "gamma = 0.99\n",
    "target_update_freq = 10\n",
    "epsilon_start = 1.0\n",
    "epsilon_end = 0.5\n",
    "epsilon_decay = 500\n",
    "num_episodes = 500\n",
    "\n",
    "def get_epsilon(episode):\n",
    "    return epsilon_end + (epsilon_start - epsilon_end) * np.exp(-1. * episode / epsilon_decay)\n",
    "\n",
    "for ep in range(num_episodes):\n",
    "    state, _ = env.reset()\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "    while not done:\n",
    "        epsilon = get_epsilon(ep)\n",
    "        if len(buffer) >= batch_size:\n",
    "            states, actions, rewards, next_states, dones = buffer.sample(batch_size)\n",
    "            states = torch.tensor(np.array(states), dtype=torch.float32)\n",
    "            actions = torch.tensor(actions, dtype=torch.int64).unsqueeze(1)\n",
    "            rewards = torch.tensor(rewards, dtype=torch.float32).unsqueeze(1)\n",
    "            next_states = torch.tensor(np.array(next_states), dtype=torch.float32)\n",
    "            dones = torch.tensor(dones, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "            q_values = policy_net(states).gather(1, actions)\n",
    "            with torch.no_grad():\n",
    "                next_q_values = target_net(next_states).max(1, keepdim=True)[0]\n",
    "                target_q_values = rewards + gamma * next_q_values * (1-dones)\n",
    "\n",
    "            loss = criterion(q_values, target_q_values)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if random.random() < epsilon:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0)\n",
    "                q_values = policy_net(state_tensor)\n",
    "                action = torch.argmax(q_values, dim=1).item()\n",
    "\n",
    "        next_state, reward, done, _, _ = env.step(action)\n",
    "        buffer.push(state, action, reward, next_state, done)\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "\n",
    "    if ep % target_update_freq == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "    print(f\"Episode {ep}, Total Reward: {total_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6493553c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_cartpole_model(model, episodes=10, render=True):\n",
    "    env = gym.make(\"CartPole-v1\", render_mode=\"human\" if render else None)\n",
    "    obs_dim = env.observation_space.shape[0]\n",
    "    n_actions = env.action_space.n\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    rewards = []\n",
    "\n",
    "    for episode in range(episodes):\n",
    "        obs, _ = env.reset()\n",
    "        total_reward = 0\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            state = torch.tensor(obs, dtype=torch.float32).unsqueeze(0)\n",
    "            with torch.no_grad():\n",
    "                q_values = model(state)\n",
    "                action = torch.argmax(q_values, dim=1).item()\n",
    "\n",
    "            obs, reward, done, _, _ = env.step(action)\n",
    "            total_reward += reward\n",
    "\n",
    "            if render:\n",
    "                env.render()\n",
    "\n",
    "        rewards.append(total_reward)\n",
    "        print(f\"Episode {episode + 1}: Reward = {total_reward}\")\n",
    "\n",
    "    env.close()\n",
    "    avg_reward = sum(rewards) / episodes\n",
    "    print(f\"Average reward over {episodes} episodes: {avg_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8643afe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Reward = 286.0\n",
      "Episode 2: Reward = 282.0\n",
      "Episode 3: Reward = 346.0\n",
      "Episode 4: Reward = 272.0\n",
      "Episode 5: Reward = 286.0\n",
      "Episode 6: Reward = 282.0\n",
      "Episode 7: Reward = 133.0\n",
      "Episode 8: Reward = 164.0\n",
      "Episode 9: Reward = 271.0\n",
      "Episode 10: Reward = 319.0\n",
      "Average reward over 10 episodes: 264.1\n"
     ]
    }
   ],
   "source": [
    "# TODO: Run evaluation for cartpole here\n",
    "evaluate_cartpole_model(policy_net, episodes=10, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b3c4213b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SnakeGame(gym.Env):\n",
    "    metadata = {\"render_modes\": [\"human\"], \"render_fps\": 10}\n",
    "\n",
    "    def __init__(self, size=10, render_mode=None):\n",
    "        super().__init__()\n",
    "        self.size = size\n",
    "        self.cell_size = 30\n",
    "        self.screen_size = self.size * self.cell_size\n",
    "        self.render_mode = render_mode\n",
    "\n",
    "        self.action_space = gym.spaces.Discrete(4)  # 0: right, 1: up, 2: left, 3: down\n",
    "        self.observation_space = gym.spaces.Box(0, 1, shape=(3, self.size, self.size), dtype=np.float32)\n",
    "\n",
    "        self.screen = None\n",
    "        self.clock = None\n",
    "\n",
    "        self.snake = deque()\n",
    "        self.food = None\n",
    "        self.direction = [1, 0]\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            pygame.init()\n",
    "            self.screen = pygame.display.set_mode((self.screen_size, self.screen_size))\n",
    "            self.clock = pygame.time.Clock()\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.snake.clear()\n",
    "        mid = self.size // 2\n",
    "        self.snake.appendleft([mid, mid])\n",
    "        self.direction = [1, 0]\n",
    "        self._place_food()\n",
    "        obs = self._get_obs()\n",
    "        self.steps_since_last_food = 0\n",
    "\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self._render_init()\n",
    "\n",
    "        return obs, {}\n",
    "    \n",
    "    def step(self, action):\n",
    "        reward = 0\n",
    "        info = {}\n",
    "        self.steps_since_last_food += 1\n",
    "        old_direction = self.direction.copy()\n",
    "\n",
    "        # --- Direction update ---\n",
    "        if action == 0 and self.direction != [-1, 0]: self.direction = [1, 0]\n",
    "        elif action == 1 and self.direction != [0, 1]: self.direction = [0, -1]\n",
    "        elif action == 2 and self.direction != [1, 0]: self.direction = [-1, 0]\n",
    "        elif action == 3 and self.direction != [0, -1]: self.direction = [0, 1]\n",
    "\n",
    "        # --- Penalize 180Â° turns ---\n",
    "        intended_direction = {\n",
    "            0: [1, 0],\n",
    "            1: [0, -1],\n",
    "            2: [-1, 0],\n",
    "            3: [0, 1],\n",
    "        }[action]\n",
    "        if intended_direction == [-d for d in old_direction]:\n",
    "            reward -= 0.5  # stronger penalty\n",
    "\n",
    "        head = self.snake[0]\n",
    "        new_head = [head[0] + self.direction[0], head[1] + self.direction[1]]\n",
    "\n",
    "        done = False\n",
    "\n",
    "        # --- Wall collision ---\n",
    "        if not (0 <= new_head[0] < self.size and 0 <= new_head[1] < self.size):\n",
    "            reward -= 10  # stronger wall penalty\n",
    "            done = True\n",
    "        else:\n",
    "            body_to_check = list(self.snake)[:-1] if new_head != self.food else list(self.snake)\n",
    "            if new_head in body_to_check:\n",
    "                reward -= 10  # stronger self-collision penalty\n",
    "                done = True\n",
    "\n",
    "        if not done:\n",
    "            self.snake.appendleft(new_head)\n",
    "\n",
    "            # --- Ate food ---\n",
    "            if new_head == self.food:\n",
    "                base = 10  # fixed base\n",
    "                time_bonus = max(15, 25 - 0.1 * self.steps_since_last_food)  # decays faster\n",
    "                reward += base + time_bonus\n",
    "                self.steps_since_last_food = 0\n",
    "                self._place_food()\n",
    "                info[\"food_eaten\"] = True\n",
    "            else:\n",
    "                self.snake.pop()\n",
    "                info[\"food_eaten\"] = False\n",
    "\n",
    "            # --- Moving closer or farther ---\n",
    "            dist_prev = abs(head[0] - self.food[0]) + abs(head[1] - self.food[1])\n",
    "            dist_new = abs(new_head[0] - self.food[0]) + abs(new_head[1] - self.food[1])\n",
    "            if dist_new < dist_prev:\n",
    "                reward += 0.3  # small positive reward\n",
    "            else:\n",
    "                reward -= 0.3  # higher negative if going away\n",
    "        else:\n",
    "            info[\"food_eaten\"] = False\n",
    "\n",
    "        obs = self._get_obs()\n",
    "        if self.render_mode == \"human\":\n",
    "            self.render()\n",
    "\n",
    "        return obs, reward, done, False, info  \n",
    "\n",
    "\n",
    "    def _get_obs(self):\n",
    "        head_grid = np.zeros((self.size, self.size), dtype=np.float32)\n",
    "        body_grid = np.zeros((self.size, self.size), dtype=np.float32)\n",
    "        food_grid = np.zeros((self.size, self.size), dtype=np.float32)\n",
    "\n",
    "        for part in list(self.snake)[1:]:\n",
    "            body_grid[part[0], part[1]] = 1.0\n",
    "        head_x, head_y = self.snake[0]\n",
    "        head_grid[head_x, head_y] = 1.0\n",
    "        food_grid[self.food[0], self.food[1]] = 1.0\n",
    "\n",
    "        stacked = np.stack([head_grid, body_grid, food_grid], axis=0)\n",
    "        return stacked.astype(np.float32)\n",
    "\n",
    "\n",
    "    def _place_food(self):\n",
    "        positions = set(tuple(p) for p in self.snake)\n",
    "        empty = [(x, y) for x in range(self.size) for y in range(self.size) if (x, y) not in positions]\n",
    "        self.food = list(random.choice(empty)) if empty else None\n",
    "\n",
    "    def render(self):\n",
    "        if self.screen is None:\n",
    "            self._render_init()\n",
    "\n",
    "        self.screen.fill((0, 0, 0))\n",
    "        for x, y in self.snake:\n",
    "            pygame.draw.rect(\n",
    "                self.screen, (0, 255, 0),\n",
    "                pygame.Rect(x * self.cell_size, y * self.cell_size, self.cell_size, self.cell_size)\n",
    "            )\n",
    "        if self.food:\n",
    "            fx, fy = self.food\n",
    "            pygame.draw.rect(\n",
    "                self.screen, (255, 0, 0),\n",
    "                pygame.Rect(fx * self.cell_size, fy * self.cell_size, self.cell_size, self.cell_size)\n",
    "            )\n",
    "\n",
    "        pygame.display.flip()\n",
    "        self.clock.tick(self.metadata[\"render_fps\"])\n",
    "\n",
    "    def _render_init(self):\n",
    "        pygame.init()\n",
    "        self.screen = pygame.display.set_mode((self.size * self.cell_size, self.size * self.cell_size))\n",
    "        self.clock = pygame.time.Clock()\n",
    "\n",
    "    def close(self):\n",
    "        if self.screen:\n",
    "            pygame.quit()\n",
    "            self.screen = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d3ffb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1, Total Reward: -14.20, Epsilon: 0.990, Steps: 15, Food: 0\n",
      "Episode 2, Total Reward: -9.00, Epsilon: 0.980, Steps: 18, Food: 0\n",
      "Episode 3, Total Reward: -13.60, Epsilon: 0.970, Steps: 16, Food: 0\n",
      "Episode 4, Total Reward: 54.80, Epsilon: 0.961, Steps: 28, Food: 2\n",
      "Episode 5, Total Reward: -13.50, Epsilon: 0.951, Steps: 10, Food: 0\n",
      "Episode 6, Total Reward: -13.10, Epsilon: 0.941, Steps: 19, Food: 0\n",
      "Episode 7, Total Reward: -12.60, Epsilon: 0.932, Steps: 8, Food: 0\n",
      "Episode 8, Total Reward: -11.10, Epsilon: 0.923, Steps: 11, Food: 0\n",
      "Episode 9, Total Reward: -11.70, Epsilon: 0.914, Steps: 11, Food: 0\n",
      "Episode 10, Total Reward: -12.20, Epsilon: 0.904, Steps: 18, Food: 0\n",
      "Episode 11, Total Reward: -11.50, Epsilon: 0.895, Steps: 11, Food: 0\n",
      "Episode 12, Total Reward: -13.40, Epsilon: 0.886, Steps: 11, Food: 0\n",
      "Episode 13, Total Reward: -14.30, Epsilon: 0.878, Steps: 23, Food: 0\n",
      "Episode 14, Total Reward: -11.10, Epsilon: 0.869, Steps: 9, Food: 0\n",
      "Episode 15, Total Reward: -13.00, Epsilon: 0.860, Steps: 18, Food: 0\n",
      "Episode 16, Total Reward: -13.00, Epsilon: 0.851, Steps: 37, Food: 0\n",
      "Episode 17, Total Reward: -13.20, Epsilon: 0.843, Steps: 7, Food: 0\n",
      "Episode 18, Total Reward: 22.60, Epsilon: 0.835, Steps: 18, Food: 1\n",
      "Episode 19, Total Reward: -15.50, Epsilon: 0.826, Steps: 26, Food: 0\n",
      "Episode 20, Total Reward: -16.90, Epsilon: 0.818, Steps: 34, Food: 0\n",
      "Episode 21, Total Reward: -13.90, Epsilon: 0.810, Steps: 16, Food: 0\n",
      "Episode 22, Total Reward: -11.00, Epsilon: 0.802, Steps: 7, Food: 0\n",
      "Episode 23, Total Reward: -12.50, Epsilon: 0.794, Steps: 17, Food: 0\n",
      "Episode 24, Total Reward: -11.40, Epsilon: 0.786, Steps: 15, Food: 0\n",
      "Episode 25, Total Reward: -13.50, Epsilon: 0.778, Steps: 8, Food: 0\n",
      "Episode 26, Total Reward: -15.40, Epsilon: 0.770, Steps: 23, Food: 0\n",
      "Episode 27, Total Reward: -14.30, Epsilon: 0.762, Steps: 44, Food: 0\n",
      "Episode 28, Total Reward: -13.10, Epsilon: 0.755, Steps: 13, Food: 0\n",
      "Episode 29, Total Reward: -12.50, Epsilon: 0.747, Steps: 6, Food: 0\n",
      "Episode 30, Total Reward: -15.10, Epsilon: 0.740, Steps: 21, Food: 0\n",
      "Episode 31, Total Reward: -11.40, Epsilon: 0.732, Steps: 12, Food: 0\n",
      "Episode 32, Total Reward: -11.90, Epsilon: 0.725, Steps: 10, Food: 0\n",
      "Episode 33, Total Reward: -15.20, Epsilon: 0.718, Steps: 32, Food: 0\n",
      "Episode 34, Total Reward: 23.00, Epsilon: 0.711, Steps: 17, Food: 1\n",
      "Episode 35, Total Reward: -13.00, Epsilon: 0.703, Steps: 8, Food: 0\n",
      "Episode 36, Total Reward: -14.20, Epsilon: 0.696, Steps: 18, Food: 0\n",
      "Episode 37, Total Reward: -15.90, Epsilon: 0.689, Steps: 43, Food: 0\n",
      "Episode 38, Total Reward: -11.90, Epsilon: 0.683, Steps: 6, Food: 0\n",
      "Episode 39, Total Reward: -10.20, Epsilon: 0.676, Steps: 10, Food: 0\n",
      "Episode 40, Total Reward: -11.40, Epsilon: 0.669, Steps: 7, Food: 0\n",
      "Episode 41, Total Reward: 26.50, Epsilon: 0.662, Steps: 15, Food: 1\n",
      "Episode 42, Total Reward: -10.20, Epsilon: 0.656, Steps: 24, Food: 0\n",
      "Episode 43, Total Reward: -10.10, Epsilon: 0.649, Steps: 10, Food: 0\n",
      "Episode 44, Total Reward: -13.20, Epsilon: 0.643, Steps: 5, Food: 0\n",
      "Episode 45, Total Reward: -11.20, Epsilon: 0.636, Steps: 8, Food: 0\n",
      "Episode 46, Total Reward: -17.00, Epsilon: 0.630, Steps: 49, Food: 0\n",
      "Episode 47, Total Reward: -11.90, Epsilon: 0.624, Steps: 6, Food: 0\n",
      "Episode 48, Total Reward: 22.50, Epsilon: 0.617, Steps: 25, Food: 1\n",
      "Episode 49, Total Reward: -14.40, Epsilon: 0.611, Steps: 9, Food: 0\n",
      "Episode 50, Total Reward: -14.50, Epsilon: 0.605, Steps: 18, Food: 0\n",
      "Episode 51, Total Reward: -12.30, Epsilon: 0.599, Steps: 10, Food: 0\n",
      "Episode 52, Total Reward: -17.80, Epsilon: 0.593, Steps: 37, Food: 0\n",
      "Episode 53, Total Reward: -11.60, Epsilon: 0.587, Steps: 18, Food: 0\n",
      "Episode 54, Total Reward: -12.80, Epsilon: 0.581, Steps: 21, Food: 0\n",
      "Episode 55, Total Reward: -13.40, Epsilon: 0.575, Steps: 18, Food: 0\n",
      "Episode 56, Total Reward: -11.70, Epsilon: 0.570, Steps: 9, Food: 0\n",
      "Episode 57, Total Reward: -13.40, Epsilon: 0.564, Steps: 13, Food: 0\n",
      "Episode 58, Total Reward: -12.60, Epsilon: 0.558, Steps: 27, Food: 0\n",
      "Episode 59, Total Reward: -11.50, Epsilon: 0.553, Steps: 7, Food: 0\n",
      "Episode 60, Total Reward: 22.10, Epsilon: 0.547, Steps: 7, Food: 1\n",
      "Episode 61, Total Reward: -11.10, Epsilon: 0.542, Steps: 9, Food: 0\n",
      "Episode 62, Total Reward: -12.70, Epsilon: 0.536, Steps: 9, Food: 0\n",
      "Episode 63, Total Reward: -13.80, Epsilon: 0.531, Steps: 15, Food: 0\n",
      "Episode 64, Total Reward: -14.80, Epsilon: 0.526, Steps: 21, Food: 0\n",
      "Episode 65, Total Reward: -14.60, Epsilon: 0.520, Steps: 19, Food: 0\n",
      "Episode 66, Total Reward: 18.50, Epsilon: 0.515, Steps: 33, Food: 1\n",
      "Episode 67, Total Reward: -11.20, Epsilon: 0.510, Steps: 12, Food: 0\n",
      "Episode 68, Total Reward: -12.00, Epsilon: 0.505, Steps: 8, Food: 0\n",
      "Episode 69, Total Reward: 24.10, Epsilon: 0.500, Steps: 9, Food: 1\n",
      "Episode 70, Total Reward: -9.30, Epsilon: 0.495, Steps: 7, Food: 0\n",
      "Episode 71, Total Reward: 122.80, Epsilon: 0.490, Steps: 42, Food: 4\n",
      "Episode 72, Total Reward: -14.80, Epsilon: 0.485, Steps: 33, Food: 0\n",
      "Episode 73, Total Reward: -15.10, Epsilon: 0.480, Steps: 38, Food: 0\n",
      "Episode 74, Total Reward: -13.60, Epsilon: 0.475, Steps: 10, Food: 0\n",
      "Episode 75, Total Reward: -14.50, Epsilon: 0.471, Steps: 22, Food: 0\n",
      "Episode 76, Total Reward: -12.80, Epsilon: 0.466, Steps: 9, Food: 0\n",
      "Episode 77, Total Reward: -11.10, Epsilon: 0.461, Steps: 22, Food: 0\n",
      "Episode 78, Total Reward: -11.20, Epsilon: 0.457, Steps: 12, Food: 0\n",
      "Episode 79, Total Reward: -14.00, Epsilon: 0.452, Steps: 24, Food: 0\n",
      "Episode 80, Total Reward: -15.00, Epsilon: 0.448, Steps: 27, Food: 0\n",
      "Episode 81, Total Reward: -15.50, Epsilon: 0.443, Steps: 40, Food: 0\n",
      "Episode 82, Total Reward: -14.80, Epsilon: 0.439, Steps: 19, Food: 0\n",
      "Episode 83, Total Reward: -13.70, Epsilon: 0.434, Steps: 32, Food: 0\n",
      "Episode 84, Total Reward: -12.40, Epsilon: 0.430, Steps: 21, Food: 0\n",
      "Episode 85, Total Reward: -15.80, Epsilon: 0.426, Steps: 23, Food: 0\n",
      "Episode 86, Total Reward: -11.90, Epsilon: 0.421, Steps: 6, Food: 0\n",
      "Episode 87, Total Reward: 18.50, Epsilon: 0.417, Steps: 43, Food: 1\n",
      "Episode 88, Total Reward: -13.90, Epsilon: 0.413, Steps: 28, Food: 0\n",
      "Episode 89, Total Reward: -11.30, Epsilon: 0.409, Steps: 21, Food: 0\n",
      "Episode 90, Total Reward: -14.10, Epsilon: 0.405, Steps: 35, Food: 0\n",
      "Episode 91, Total Reward: -13.30, Epsilon: 0.401, Steps: 13, Food: 0\n",
      "Episode 92, Total Reward: -13.10, Epsilon: 0.397, Steps: 17, Food: 0\n",
      "Episode 93, Total Reward: -10.90, Epsilon: 0.393, Steps: 17, Food: 0\n",
      "Episode 94, Total Reward: -16.00, Epsilon: 0.389, Steps: 22, Food: 0\n",
      "Episode 95, Total Reward: -12.60, Epsilon: 0.385, Steps: 15, Food: 0\n",
      "Episode 96, Total Reward: -19.60, Epsilon: 0.381, Steps: 73, Food: 0\n",
      "Episode 97, Total Reward: -13.40, Epsilon: 0.377, Steps: 18, Food: 0\n",
      "Episode 98, Total Reward: -13.10, Epsilon: 0.373, Steps: 18, Food: 0\n",
      "Episode 99, Total Reward: 20.20, Epsilon: 0.370, Steps: 35, Food: 1\n",
      "Episode 100, Total Reward: -12.00, Epsilon: 0.366, Steps: 12, Food: 0\n",
      "Episode 101, Total Reward: -12.40, Epsilon: 0.362, Steps: 10, Food: 0\n",
      "Episode 102, Total Reward: -19.10, Epsilon: 0.359, Steps: 40, Food: 0\n",
      "Episode 103, Total Reward: -12.20, Epsilon: 0.355, Steps: 21, Food: 0\n",
      "Episode 104, Total Reward: 17.70, Epsilon: 0.352, Steps: 33, Food: 1\n",
      "Episode 105, Total Reward: 51.80, Epsilon: 0.348, Steps: 36, Food: 2\n",
      "Episode 106, Total Reward: -16.90, Epsilon: 0.345, Steps: 42, Food: 0\n",
      "Episode 107, Total Reward: 23.10, Epsilon: 0.341, Steps: 19, Food: 1\n",
      "Episode 108, Total Reward: -10.40, Epsilon: 0.338, Steps: 11, Food: 0\n",
      "Episode 109, Total Reward: -13.80, Epsilon: 0.334, Steps: 17, Food: 0\n",
      "Episode 110, Total Reward: 54.70, Epsilon: 0.331, Steps: 28, Food: 2\n",
      "Episode 111, Total Reward: -11.80, Epsilon: 0.328, Steps: 22, Food: 0\n",
      "Episode 112, Total Reward: -14.90, Epsilon: 0.324, Steps: 29, Food: 0\n",
      "Episode 113, Total Reward: -15.10, Epsilon: 0.321, Steps: 33, Food: 0\n",
      "Episode 114, Total Reward: -10.80, Epsilon: 0.318, Steps: 6, Food: 0\n",
      "Episode 115, Total Reward: -11.90, Epsilon: 0.315, Steps: 10, Food: 0\n",
      "Episode 116, Total Reward: -14.90, Epsilon: 0.312, Steps: 48, Food: 0\n",
      "Episode 117, Total Reward: -15.90, Epsilon: 0.309, Steps: 26, Food: 0\n",
      "Episode 118, Total Reward: 20.70, Epsilon: 0.305, Steps: 27, Food: 1\n",
      "Episode 119, Total Reward: -9.80, Epsilon: 0.302, Steps: 7, Food: 0\n",
      "Episode 120, Total Reward: -12.60, Epsilon: 0.299, Steps: 14, Food: 0\n",
      "Episode 121, Total Reward: -12.00, Epsilon: 0.296, Steps: 10, Food: 0\n",
      "Episode 122, Total Reward: -14.00, Epsilon: 0.293, Steps: 20, Food: 0\n",
      "Episode 123, Total Reward: -13.00, Epsilon: 0.290, Steps: 11, Food: 0\n",
      "Episode 124, Total Reward: -14.10, Epsilon: 0.288, Steps: 17, Food: 0\n",
      "Episode 125, Total Reward: -14.60, Epsilon: 0.285, Steps: 26, Food: 0\n",
      "Episode 126, Total Reward: 19.30, Epsilon: 0.282, Steps: 29, Food: 1\n",
      "Episode 127, Total Reward: 22.30, Epsilon: 0.279, Steps: 13, Food: 1\n",
      "Episode 128, Total Reward: -18.40, Epsilon: 0.276, Steps: 37, Food: 0\n",
      "Episode 129, Total Reward: -15.60, Epsilon: 0.273, Steps: 22, Food: 0\n",
      "Episode 130, Total Reward: -15.60, Epsilon: 0.271, Steps: 32, Food: 0\n",
      "Episode 131, Total Reward: -10.00, Epsilon: 0.268, Steps: 9, Food: 0\n",
      "Episode 132, Total Reward: -15.20, Epsilon: 0.265, Steps: 36, Food: 0\n",
      "Episode 133, Total Reward: -13.60, Epsilon: 0.263, Steps: 41, Food: 0\n",
      "Episode 134, Total Reward: -12.80, Epsilon: 0.260, Steps: 7, Food: 0\n",
      "Episode 135, Total Reward: 55.80, Epsilon: 0.257, Steps: 24, Food: 2\n",
      "Episode 136, Total Reward: 23.10, Epsilon: 0.255, Steps: 24, Food: 1\n",
      "Episode 137, Total Reward: -13.00, Epsilon: 0.252, Steps: 6, Food: 0\n",
      "Episode 138, Total Reward: -13.60, Epsilon: 0.250, Steps: 16, Food: 0\n",
      "Episode 139, Total Reward: 20.70, Epsilon: 0.247, Steps: 48, Food: 1\n",
      "Episode 140, Total Reward: -17.70, Epsilon: 0.245, Steps: 34, Food: 0\n",
      "Episode 141, Total Reward: -11.40, Epsilon: 0.242, Steps: 21, Food: 0\n",
      "Episode 142, Total Reward: -15.00, Epsilon: 0.240, Steps: 31, Food: 0\n",
      "Episode 143, Total Reward: -17.80, Epsilon: 0.238, Steps: 57, Food: 0\n",
      "Episode 144, Total Reward: 22.10, Epsilon: 0.235, Steps: 19, Food: 1\n",
      "Episode 145, Total Reward: -11.30, Epsilon: 0.233, Steps: 21, Food: 0\n",
      "Episode 146, Total Reward: -13.50, Epsilon: 0.231, Steps: 13, Food: 0\n",
      "Episode 147, Total Reward: -15.10, Epsilon: 0.228, Steps: 18, Food: 0\n",
      "Episode 148, Total Reward: -11.90, Epsilon: 0.226, Steps: 12, Food: 0\n",
      "Episode 149, Total Reward: 19.30, Epsilon: 0.224, Steps: 39, Food: 1\n",
      "Episode 150, Total Reward: -20.40, Epsilon: 0.221, Steps: 82, Food: 0\n",
      "Episode 151, Total Reward: 15.80, Epsilon: 0.219, Steps: 78, Food: 1\n",
      "Episode 152, Total Reward: -15.20, Epsilon: 0.217, Steps: 21, Food: 0\n",
      "Episode 153, Total Reward: 21.00, Epsilon: 0.215, Steps: 16, Food: 1\n",
      "Episode 154, Total Reward: -18.00, Epsilon: 0.213, Steps: 38, Food: 0\n",
      "Episode 155, Total Reward: -15.10, Epsilon: 0.211, Steps: 16, Food: 0\n",
      "Episode 156, Total Reward: -25.70, Epsilon: 0.208, Steps: 95, Food: 0\n",
      "Episode 157, Total Reward: -25.20, Epsilon: 0.206, Steps: 101, Food: 0\n",
      "Episode 158, Total Reward: 83.10, Epsilon: 0.204, Steps: 85, Food: 3\n",
      "Episode 159, Total Reward: -15.20, Epsilon: 0.202, Steps: 10, Food: 0\n",
      "Episode 160, Total Reward: -18.80, Epsilon: 0.200, Steps: 53, Food: 0\n",
      "Episode 161, Total Reward: -15.40, Epsilon: 0.198, Steps: 29, Food: 0\n",
      "Episode 162, Total Reward: -12.20, Epsilon: 0.196, Steps: 19, Food: 0\n",
      "Episode 163, Total Reward: -16.00, Epsilon: 0.194, Steps: 32, Food: 0\n",
      "Episode 164, Total Reward: -13.80, Epsilon: 0.192, Steps: 19, Food: 0\n",
      "Episode 165, Total Reward: -14.50, Epsilon: 0.190, Steps: 29, Food: 0\n",
      "Episode 166, Total Reward: -16.40, Epsilon: 0.189, Steps: 21, Food: 0\n",
      "Episode 167, Total Reward: 21.10, Epsilon: 0.187, Steps: 28, Food: 1\n",
      "Episode 168, Total Reward: -18.40, Epsilon: 0.185, Steps: 42, Food: 0\n",
      "Episode 169, Total Reward: -15.40, Epsilon: 0.183, Steps: 19, Food: 0\n",
      "Episode 170, Total Reward: -24.40, Epsilon: 0.181, Steps: 78, Food: 0\n",
      "Episode 171, Total Reward: -15.60, Epsilon: 0.179, Steps: 19, Food: 0\n",
      "Episode 172, Total Reward: 118.10, Epsilon: 0.178, Steps: 68, Food: 4\n",
      "Episode 173, Total Reward: 21.20, Epsilon: 0.176, Steps: 25, Food: 1\n",
      "Episode 174, Total Reward: -16.90, Epsilon: 0.174, Steps: 45, Food: 0\n",
      "Episode 175, Total Reward: 9.60, Epsilon: 0.172, Steps: 64, Food: 1\n",
      "Episode 176, Total Reward: -15.50, Epsilon: 0.171, Steps: 33, Food: 0\n",
      "Episode 177, Total Reward: -13.90, Epsilon: 0.169, Steps: 33, Food: 0\n",
      "Episode 178, Total Reward: -13.10, Epsilon: 0.167, Steps: 25, Food: 0\n",
      "Episode 179, Total Reward: 23.80, Epsilon: 0.165, Steps: 14, Food: 1\n",
      "Episode 180, Total Reward: -12.50, Epsilon: 0.164, Steps: 11, Food: 0\n",
      "Episode 181, Total Reward: -13.50, Epsilon: 0.162, Steps: 14, Food: 0\n",
      "Episode 182, Total Reward: 80.70, Epsilon: 0.161, Steps: 109, Food: 3\n",
      "Episode 183, Total Reward: 13.50, Epsilon: 0.159, Steps: 94, Food: 1\n",
      "Episode 184, Total Reward: 39.90, Epsilon: 0.157, Steps: 158, Food: 2\n",
      "Episode 185, Total Reward: -13.50, Epsilon: 0.156, Steps: 13, Food: 0\n",
      "Episode 186, Total Reward: -14.20, Epsilon: 0.154, Steps: 22, Food: 0\n",
      "Episode 187, Total Reward: 24.60, Epsilon: 0.153, Steps: 10, Food: 1\n",
      "Episode 188, Total Reward: -25.50, Epsilon: 0.151, Steps: 112, Food: 0\n",
      "Episode 189, Total Reward: 15.20, Epsilon: 0.150, Steps: 119, Food: 1\n",
      "Episode 190, Total Reward: -14.60, Epsilon: 0.148, Steps: 26, Food: 0\n",
      "Episode 191, Total Reward: -24.90, Epsilon: 0.147, Steps: 119, Food: 0\n",
      "Episode 192, Total Reward: -17.40, Epsilon: 0.145, Steps: 74, Food: 0\n",
      "Episode 193, Total Reward: -51.10, Epsilon: 0.144, Steps: 280, Food: 0\n",
      "Episode 194, Total Reward: -11.80, Epsilon: 0.142, Steps: 400, Food: 1\n",
      "Episode 195, Total Reward: -15.70, Epsilon: 0.141, Steps: 23, Food: 0\n",
      "Episode 196, Total Reward: -9.10, Epsilon: 0.139, Steps: 21, Food: 0\n",
      "Episode 197, Total Reward: -11.30, Epsilon: 0.138, Steps: 5, Food: 0\n",
      "Episode 198, Total Reward: 23.00, Epsilon: 0.137, Steps: 12, Food: 1\n",
      "Episode 199, Total Reward: 9.90, Epsilon: 0.135, Steps: 99, Food: 1\n",
      "Episode 200, Total Reward: -20.00, Epsilon: 0.134, Steps: 87, Food: 0\n",
      "Episode 201, Total Reward: -15.30, Epsilon: 0.133, Steps: 49, Food: 0\n",
      "Episode 202, Total Reward: 50.90, Epsilon: 0.131, Steps: 72, Food: 2\n",
      "Episode 203, Total Reward: -30.30, Epsilon: 0.130, Steps: 152, Food: 0\n",
      "Episode 204, Total Reward: 51.30, Epsilon: 0.129, Steps: 84, Food: 2\n",
      "Episode 205, Total Reward: 41.90, Epsilon: 0.127, Steps: 89, Food: 2\n",
      "Episode 206, Total Reward: -12.10, Epsilon: 0.126, Steps: 9, Food: 0\n",
      "Episode 207, Total Reward: -12.60, Epsilon: 0.125, Steps: 11, Food: 0\n",
      "Episode 208, Total Reward: -10.90, Epsilon: 0.124, Steps: 11, Food: 0\n",
      "Episode 209, Total Reward: -11.40, Epsilon: 0.122, Steps: 13, Food: 0\n",
      "Episode 210, Total Reward: 16.90, Epsilon: 0.121, Steps: 38, Food: 1\n",
      "Episode 211, Total Reward: -13.80, Epsilon: 0.120, Steps: 7, Food: 0\n",
      "Episode 212, Total Reward: 22.70, Epsilon: 0.119, Steps: 10, Food: 1\n",
      "Episode 213, Total Reward: 45.80, Epsilon: 0.118, Steps: 72, Food: 2\n",
      "Episode 214, Total Reward: -22.30, Epsilon: 0.116, Steps: 65, Food: 0\n",
      "Episode 215, Total Reward: -13.20, Epsilon: 0.115, Steps: 33, Food: 0\n",
      "Episode 216, Total Reward: 34.20, Epsilon: 0.114, Steps: 126, Food: 2\n",
      "Episode 217, Total Reward: -16.40, Epsilon: 0.113, Steps: 106, Food: 0\n",
      "Episode 218, Total Reward: 57.10, Epsilon: 0.112, Steps: 60, Food: 2\n",
      "Episode 219, Total Reward: -23.40, Epsilon: 0.111, Steps: 63, Food: 0\n",
      "Episode 220, Total Reward: -14.00, Epsilon: 0.110, Steps: 54, Food: 0\n",
      "Episode 221, Total Reward: -20.20, Epsilon: 0.108, Steps: 46, Food: 0\n",
      "Episode 222, Total Reward: -19.20, Epsilon: 0.107, Steps: 112, Food: 0\n",
      "Episode 223, Total Reward: 20.00, Epsilon: 0.106, Steps: 18, Food: 1\n",
      "Episode 224, Total Reward: -13.20, Epsilon: 0.105, Steps: 7, Food: 0\n",
      "Episode 225, Total Reward: -19.90, Epsilon: 0.104, Steps: 60, Food: 0\n",
      "Episode 226, Total Reward: 45.60, Epsilon: 0.103, Steps: 400, Food: 3\n",
      "Episode 227, Total Reward: -10.50, Epsilon: 0.102, Steps: 10, Food: 0\n",
      "Episode 228, Total Reward: 0.80, Epsilon: 0.101, Steps: 180, Food: 1\n",
      "Episode 229, Total Reward: -28.30, Epsilon: 0.100, Steps: 149, Food: 0\n",
      "Episode 230, Total Reward: -20.20, Epsilon: 0.099, Steps: 57, Food: 0\n",
      "Episode 231, Total Reward: -15.80, Epsilon: 0.098, Steps: 85, Food: 0\n",
      "Episode 232, Total Reward: 63.70, Epsilon: 0.097, Steps: 235, Food: 3\n",
      "Episode 233, Total Reward: 13.70, Epsilon: 0.096, Steps: 68, Food: 1\n",
      "Episode 234, Total Reward: 9.50, Epsilon: 0.095, Steps: 138, Food: 1\n",
      "Episode 235, Total Reward: -14.60, Epsilon: 0.094, Steps: 25, Food: 0\n",
      "Episode 236, Total Reward: -23.70, Epsilon: 0.093, Steps: 103, Food: 0\n",
      "Episode 237, Total Reward: -11.60, Epsilon: 0.092, Steps: 17, Food: 0\n",
      "Episode 238, Total Reward: -12.00, Epsilon: 0.091, Steps: 9, Food: 0\n",
      "Episode 239, Total Reward: 9.80, Epsilon: 0.091, Steps: 116, Food: 1\n",
      "Episode 240, Total Reward: -12.20, Epsilon: 0.090, Steps: 17, Food: 0\n",
      "Episode 241, Total Reward: 4.30, Epsilon: 0.089, Steps: 127, Food: 1\n",
      "Episode 242, Total Reward: -14.00, Epsilon: 0.088, Steps: 19, Food: 0\n",
      "Episode 243, Total Reward: -17.40, Epsilon: 0.087, Steps: 21, Food: 0\n",
      "Episode 244, Total Reward: -16.00, Epsilon: 0.086, Steps: 44, Food: 0\n",
      "Episode 245, Total Reward: -14.10, Epsilon: 0.085, Steps: 33, Food: 0\n",
      "Episode 246, Total Reward: -12.70, Epsilon: 0.084, Steps: 22, Food: 0\n",
      "Episode 247, Total Reward: -16.50, Epsilon: 0.084, Steps: 26, Food: 0\n",
      "Episode 248, Total Reward: -16.50, Epsilon: 0.083, Steps: 28, Food: 0\n",
      "Episode 249, Total Reward: 8.00, Epsilon: 0.082, Steps: 84, Food: 1\n",
      "Episode 250, Total Reward: -10.40, Epsilon: 0.081, Steps: 12, Food: 0\n",
      "Episode 251, Total Reward: -14.10, Epsilon: 0.080, Steps: 33, Food: 0\n",
      "Episode 252, Total Reward: -17.60, Epsilon: 0.079, Steps: 90, Food: 0\n",
      "Episode 253, Total Reward: -14.00, Epsilon: 0.079, Steps: 16, Food: 0\n",
      "Episode 254, Total Reward: -14.60, Epsilon: 0.078, Steps: 22, Food: 0\n",
      "Episode 255, Total Reward: -16.90, Epsilon: 0.077, Steps: 19, Food: 0\n",
      "Episode 256, Total Reward: 107.80, Epsilon: 0.076, Steps: 145, Food: 4\n",
      "Episode 257, Total Reward: -23.00, Epsilon: 0.076, Steps: 87, Food: 0\n",
      "Episode 258, Total Reward: 31.50, Epsilon: 0.075, Steps: 196, Food: 2\n",
      "Episode 259, Total Reward: -16.60, Epsilon: 0.074, Steps: 33, Food: 0\n",
      "Episode 260, Total Reward: 8.60, Epsilon: 0.073, Steps: 102, Food: 1\n",
      "Episode 261, Total Reward: 8.00, Epsilon: 0.073, Steps: 242, Food: 1\n",
      "Episode 262, Total Reward: -21.60, Epsilon: 0.072, Steps: 52, Food: 0\n",
      "Episode 263, Total Reward: -13.80, Epsilon: 0.071, Steps: 7, Food: 0\n",
      "Episode 264, Total Reward: -3.20, Epsilon: 0.070, Steps: 137, Food: 1\n",
      "Episode 265, Total Reward: -33.40, Epsilon: 0.070, Steps: 195, Food: 0\n",
      "Episode 266, Total Reward: -18.00, Epsilon: 0.069, Steps: 400, Food: 1\n",
      "Episode 267, Total Reward: 18.10, Epsilon: 0.068, Steps: 340, Food: 2\n",
      "Episode 268, Total Reward: -14.60, Epsilon: 0.068, Steps: 32, Food: 0\n",
      "Episode 269, Total Reward: -21.50, Epsilon: 0.067, Steps: 80, Food: 0\n",
      "Episode 270, Total Reward: -9.50, Epsilon: 0.066, Steps: 12, Food: 0\n",
      "Episode 271, Total Reward: 108.80, Epsilon: 0.066, Steps: 316, Food: 5\n",
      "Episode 272, Total Reward: -19.30, Epsilon: 0.065, Steps: 54, Food: 0\n",
      "Episode 273, Total Reward: -34.70, Epsilon: 0.064, Steps: 127, Food: 0\n",
      "Episode 274, Total Reward: -23.00, Epsilon: 0.064, Steps: 73, Food: 0\n",
      "Episode 275, Total Reward: -14.30, Epsilon: 0.063, Steps: 26, Food: 0\n",
      "Episode 276, Total Reward: -40.10, Epsilon: 0.062, Steps: 252, Food: 0\n",
      "Episode 277, Total Reward: -18.90, Epsilon: 0.062, Steps: 88, Food: 0\n",
      "Episode 278, Total Reward: 20.70, Epsilon: 0.061, Steps: 274, Food: 2\n",
      "Episode 279, Total Reward: 52.60, Epsilon: 0.061, Steps: 268, Food: 3\n",
      "Episode 280, Total Reward: 28.60, Epsilon: 0.060, Steps: 259, Food: 2\n",
      "Episode 281, Total Reward: 14.90, Epsilon: 0.059, Steps: 70, Food: 1\n",
      "Episode 282, Total Reward: -17.40, Epsilon: 0.059, Steps: 45, Food: 0\n",
      "Episode 283, Total Reward: -40.60, Epsilon: 0.058, Steps: 376, Food: 0\n",
      "Episode 284, Total Reward: -17.30, Epsilon: 0.058, Steps: 65, Food: 0\n",
      "Episode 285, Total Reward: 24.50, Epsilon: 0.057, Steps: 9, Food: 1\n",
      "Episode 286, Total Reward: 59.90, Epsilon: 0.056, Steps: 39, Food: 2\n",
      "Episode 287, Total Reward: -14.20, Epsilon: 0.056, Steps: 33, Food: 0\n",
      "Episode 288, Total Reward: 56.70, Epsilon: 0.055, Steps: 271, Food: 3\n",
      "Episode 289, Total Reward: -11.90, Epsilon: 0.055, Steps: 5, Food: 0\n",
      "Episode 290, Total Reward: -14.80, Epsilon: 0.054, Steps: 24, Food: 0\n",
      "Episode 291, Total Reward: 50.70, Epsilon: 0.054, Steps: 247, Food: 3\n",
      "Episode 292, Total Reward: 2.90, Epsilon: 0.053, Steps: 400, Food: 1\n",
      "Episode 293, Total Reward: -11.50, Epsilon: 0.053, Steps: 400, Food: 1\n",
      "Episode 294, Total Reward: -18.20, Epsilon: 0.052, Steps: 35, Food: 0\n",
      "Episode 295, Total Reward: 52.20, Epsilon: 0.052, Steps: 55, Food: 2\n",
      "Episode 296, Total Reward: -15.60, Epsilon: 0.051, Steps: 27, Food: 0\n",
      "Episode 297, Total Reward: 15.90, Epsilon: 0.051, Steps: 40, Food: 1\n",
      "Episode 298, Total Reward: -25.30, Epsilon: 0.050, Steps: 113, Food: 0\n",
      "Episode 299, Total Reward: 79.60, Epsilon: 0.050, Steps: 95, Food: 3\n",
      "Episode 300, Total Reward: -13.70, Epsilon: 0.049, Steps: 10, Food: 0\n",
      "Episode 301, Total Reward: 97.90, Epsilon: 0.049, Steps: 231, Food: 4\n",
      "Episode 302, Total Reward: -14.60, Epsilon: 0.048, Steps: 11, Food: 0\n",
      "Episode 303, Total Reward: -16.20, Epsilon: 0.048, Steps: 26, Food: 0\n",
      "Episode 304, Total Reward: 20.20, Epsilon: 0.047, Steps: 33, Food: 1\n",
      "Episode 305, Total Reward: -15.50, Epsilon: 0.047, Steps: 20, Food: 0\n",
      "Episode 306, Total Reward: 14.60, Epsilon: 0.046, Steps: 70, Food: 1\n",
      "Episode 307, Total Reward: -1.50, Epsilon: 0.046, Steps: 236, Food: 1\n",
      "Episode 308, Total Reward: 47.10, Epsilon: 0.045, Steps: 104, Food: 2\n",
      "Episode 309, Total Reward: 16.80, Epsilon: 0.045, Steps: 101, Food: 1\n",
      "Episode 310, Total Reward: 16.40, Epsilon: 0.044, Steps: 400, Food: 2\n",
      "Episode 311, Total Reward: -13.70, Epsilon: 0.044, Steps: 5, Food: 0\n",
      "Episode 312, Total Reward: -20.70, Epsilon: 0.043, Steps: 106, Food: 0\n",
      "Episode 313, Total Reward: 17.40, Epsilon: 0.043, Steps: 311, Food: 2\n",
      "Episode 314, Total Reward: -17.50, Epsilon: 0.043, Steps: 82, Food: 0\n",
      "Episode 315, Total Reward: -24.40, Epsilon: 0.042, Steps: 119, Food: 0\n",
      "Episode 316, Total Reward: 7.80, Epsilon: 0.042, Steps: 400, Food: 2\n",
      "Episode 317, Total Reward: -14.30, Epsilon: 0.041, Steps: 10, Food: 0\n",
      "Episode 318, Total Reward: 76.20, Epsilon: 0.041, Steps: 167, Food: 3\n",
      "Episode 319, Total Reward: -18.80, Epsilon: 0.041, Steps: 37, Food: 0\n",
      "Episode 320, Total Reward: -15.10, Epsilon: 0.040, Steps: 27, Food: 0\n",
      "Episode 321, Total Reward: -11.70, Epsilon: 0.040, Steps: 18, Food: 0\n",
      "Episode 322, Total Reward: 108.60, Epsilon: 0.039, Steps: 237, Food: 4\n",
      "Episode 323, Total Reward: -16.30, Epsilon: 0.039, Steps: 36, Food: 0\n",
      "Episode 324, Total Reward: -9.00, Epsilon: 0.039, Steps: 8, Food: 0\n",
      "Episode 325, Total Reward: -13.50, Epsilon: 0.038, Steps: 25, Food: 0\n",
      "Episode 326, Total Reward: -14.60, Epsilon: 0.038, Steps: 20, Food: 0\n",
      "Episode 327, Total Reward: 46.00, Epsilon: 0.037, Steps: 369, Food: 3\n",
      "Episode 328, Total Reward: 14.30, Epsilon: 0.037, Steps: 189, Food: 1\n",
      "Episode 329, Total Reward: 26.40, Epsilon: 0.037, Steps: 27, Food: 1\n",
      "Episode 330, Total Reward: -12.60, Epsilon: 0.036, Steps: 400, Food: 1\n",
      "Episode 331, Total Reward: -12.40, Epsilon: 0.036, Steps: 17, Food: 0\n",
      "Episode 332, Total Reward: 106.70, Epsilon: 0.036, Steps: 120, Food: 4\n",
      "Episode 333, Total Reward: 18.50, Epsilon: 0.035, Steps: 55, Food: 1\n",
      "Episode 334, Total Reward: -66.00, Epsilon: 0.035, Steps: 386, Food: 0\n",
      "Episode 335, Total Reward: 21.50, Epsilon: 0.034, Steps: 21, Food: 1\n",
      "Episode 336, Total Reward: -17.60, Epsilon: 0.034, Steps: 59, Food: 0\n",
      "Episode 337, Total Reward: 18.80, Epsilon: 0.034, Steps: 47, Food: 1\n",
      "Episode 338, Total Reward: -19.60, Epsilon: 0.033, Steps: 60, Food: 0\n",
      "Episode 339, Total Reward: -24.70, Epsilon: 0.033, Steps: 87, Food: 0\n",
      "Episode 340, Total Reward: -12.30, Epsilon: 0.033, Steps: 20, Food: 0\n",
      "Episode 341, Total Reward: 27.80, Epsilon: 0.032, Steps: 340, Food: 3\n",
      "Episode 342, Total Reward: -38.90, Epsilon: 0.032, Steps: 400, Food: 0\n",
      "Episode 343, Total Reward: 66.50, Epsilon: 0.032, Steps: 159, Food: 3\n",
      "Episode 344, Total Reward: 12.80, Epsilon: 0.032, Steps: 88, Food: 1\n",
      "Episode 345, Total Reward: 37.10, Epsilon: 0.031, Steps: 219, Food: 2\n",
      "Episode 346, Total Reward: 102.50, Epsilon: 0.031, Steps: 146, Food: 4\n",
      "Episode 347, Total Reward: 2.60, Epsilon: 0.031, Steps: 124, Food: 1\n",
      "Episode 348, Total Reward: 19.40, Epsilon: 0.030, Steps: 27, Food: 1\n",
      "Episode 349, Total Reward: 46.50, Epsilon: 0.030, Steps: 78, Food: 2\n",
      "Episode 350, Total Reward: -17.40, Epsilon: 0.030, Steps: 33, Food: 0\n",
      "Episode 351, Total Reward: -14.70, Epsilon: 0.029, Steps: 26, Food: 0\n",
      "Episode 352, Total Reward: -13.00, Epsilon: 0.029, Steps: 6, Food: 0\n",
      "Episode 353, Total Reward: 15.60, Epsilon: 0.029, Steps: 74, Food: 1\n",
      "Episode 354, Total Reward: 18.60, Epsilon: 0.029, Steps: 32, Food: 1\n",
      "Episode 355, Total Reward: -13.00, Epsilon: 0.028, Steps: 6, Food: 0\n",
      "Episode 356, Total Reward: -20.40, Epsilon: 0.028, Steps: 76, Food: 0\n",
      "Episode 357, Total Reward: 30.10, Epsilon: 0.028, Steps: 172, Food: 2\n",
      "Episode 358, Total Reward: 86.20, Epsilon: 0.027, Steps: 43, Food: 3\n",
      "Episode 359, Total Reward: -18.40, Epsilon: 0.027, Steps: 29, Food: 0\n",
      "Episode 360, Total Reward: 39.30, Epsilon: 0.027, Steps: 345, Food: 3\n",
      "Episode 361, Total Reward: -20.80, Epsilon: 0.027, Steps: 67, Food: 0\n",
      "Episode 362, Total Reward: -47.90, Epsilon: 0.026, Steps: 237, Food: 0\n",
      "Episode 363, Total Reward: 62.40, Epsilon: 0.026, Steps: 183, Food: 3\n",
      "Episode 364, Total Reward: -14.50, Epsilon: 0.026, Steps: 38, Food: 0\n",
      "Episode 365, Total Reward: -23.20, Epsilon: 0.026, Steps: 166, Food: 0\n",
      "Episode 366, Total Reward: -17.20, Epsilon: 0.025, Steps: 34, Food: 0\n",
      "Episode 367, Total Reward: 19.00, Epsilon: 0.025, Steps: 42, Food: 1\n",
      "Episode 368, Total Reward: -6.20, Epsilon: 0.025, Steps: 208, Food: 1\n",
      "Episode 369, Total Reward: -18.70, Epsilon: 0.025, Steps: 42, Food: 0\n",
      "Episode 370, Total Reward: -13.30, Epsilon: 0.024, Steps: 12, Food: 0\n",
      "Episode 371, Total Reward: -10.30, Epsilon: 0.024, Steps: 23, Food: 0\n",
      "Episode 372, Total Reward: 100.30, Epsilon: 0.024, Steps: 168, Food: 4\n",
      "Episode 373, Total Reward: -13.70, Epsilon: 0.024, Steps: 19, Food: 0\n",
      "Episode 374, Total Reward: -18.70, Epsilon: 0.023, Steps: 41, Food: 0\n",
      "Episode 375, Total Reward: 42.90, Epsilon: 0.023, Steps: 103, Food: 2\n",
      "Episode 376, Total Reward: 3.30, Epsilon: 0.023, Steps: 184, Food: 1\n",
      "Episode 377, Total Reward: -22.80, Epsilon: 0.023, Steps: 192, Food: 0\n",
      "Episode 378, Total Reward: -12.00, Epsilon: 0.022, Steps: 15, Food: 0\n",
      "Episode 379, Total Reward: -14.70, Epsilon: 0.022, Steps: 39, Food: 0\n",
      "Episode 380, Total Reward: -19.10, Epsilon: 0.022, Steps: 30, Food: 0\n",
      "Episode 381, Total Reward: 49.80, Epsilon: 0.022, Steps: 56, Food: 2\n",
      "Episode 382, Total Reward: -13.30, Epsilon: 0.022, Steps: 400, Food: 1\n",
      "Episode 383, Total Reward: -23.90, Epsilon: 0.021, Steps: 86, Food: 0\n",
      "Episode 384, Total Reward: -19.90, Epsilon: 0.021, Steps: 52, Food: 0\n",
      "Episode 385, Total Reward: 20.20, Epsilon: 0.021, Steps: 62, Food: 1\n",
      "Episode 386, Total Reward: -34.80, Epsilon: 0.021, Steps: 128, Food: 0\n",
      "Episode 387, Total Reward: -19.70, Epsilon: 0.020, Steps: 26, Food: 0\n",
      "Episode 388, Total Reward: 59.30, Epsilon: 0.020, Steps: 333, Food: 3\n",
      "Episode 389, Total Reward: 99.80, Epsilon: 0.020, Steps: 398, Food: 5\n",
      "Episode 390, Total Reward: 19.00, Epsilon: 0.020, Steps: 42, Food: 1\n",
      "Episode 391, Total Reward: 165.50, Epsilon: 0.020, Steps: 205, Food: 6\n",
      "Episode 392, Total Reward: 123.10, Epsilon: 0.019, Steps: 103, Food: 4\n",
      "Episode 393, Total Reward: -24.70, Epsilon: 0.019, Steps: 107, Food: 0\n",
      "Episode 394, Total Reward: 20.90, Epsilon: 0.019, Steps: 21, Food: 1\n",
      "Episode 395, Total Reward: 21.20, Epsilon: 0.019, Steps: 14, Food: 1\n",
      "Episode 396, Total Reward: 151.10, Epsilon: 0.019, Steps: 311, Food: 6\n",
      "Episode 397, Total Reward: 7.50, Epsilon: 0.019, Steps: 101, Food: 1\n",
      "Episode 398, Total Reward: 22.90, Epsilon: 0.018, Steps: 238, Food: 2\n",
      "Episode 399, Total Reward: 53.10, Epsilon: 0.018, Steps: 400, Food: 3\n",
      "Episode 400, Total Reward: 37.50, Epsilon: 0.018, Steps: 400, Food: 2\n",
      "Episode 401, Total Reward: -12.90, Epsilon: 0.018, Steps: 299, Food: 1\n",
      "Episode 402, Total Reward: -15.50, Epsilon: 0.018, Steps: 27, Food: 0\n",
      "Episode 403, Total Reward: -19.00, Epsilon: 0.017, Steps: 44, Food: 0\n",
      "Episode 404, Total Reward: -34.70, Epsilon: 0.017, Steps: 332, Food: 0\n",
      "Episode 405, Total Reward: 83.40, Epsilon: 0.017, Steps: 78, Food: 3\n",
      "Episode 406, Total Reward: 163.60, Epsilon: 0.017, Steps: 310, Food: 6\n",
      "Episode 407, Total Reward: 117.80, Epsilon: 0.017, Steps: 110, Food: 4\n",
      "Episode 408, Total Reward: 164.40, Epsilon: 0.017, Steps: 76, Food: 5\n",
      "Episode 409, Total Reward: 82.40, Epsilon: 0.016, Steps: 128, Food: 3\n",
      "Episode 410, Total Reward: 16.10, Epsilon: 0.016, Steps: 86, Food: 1\n",
      "Episode 411, Total Reward: 85.60, Epsilon: 0.016, Steps: 308, Food: 4\n",
      "Episode 412, Total Reward: -15.00, Epsilon: 0.016, Steps: 24, Food: 0\n",
      "Episode 413, Total Reward: 72.50, Epsilon: 0.016, Steps: 99, Food: 3\n",
      "Episode 414, Total Reward: -10.70, Epsilon: 0.016, Steps: 6, Food: 0\n",
      "Episode 415, Total Reward: 68.50, Epsilon: 0.015, Steps: 255, Food: 3\n",
      "Episode 416, Total Reward: -15.40, Epsilon: 0.015, Steps: 11, Food: 0\n",
      "Episode 417, Total Reward: 31.00, Epsilon: 0.015, Steps: 131, Food: 2\n",
      "Episode 418, Total Reward: -12.40, Epsilon: 0.015, Steps: 12, Food: 0\n",
      "Episode 419, Total Reward: 43.90, Epsilon: 0.015, Steps: 92, Food: 2\n",
      "Episode 420, Total Reward: 51.60, Epsilon: 0.015, Steps: 37, Food: 2\n",
      "Episode 421, Total Reward: 98.80, Epsilon: 0.015, Steps: 243, Food: 4\n",
      "Episode 422, Total Reward: -30.40, Epsilon: 0.014, Steps: 183, Food: 0\n",
      "Episode 423, Total Reward: -19.60, Epsilon: 0.014, Steps: 57, Food: 0\n",
      "Episode 424, Total Reward: 70.20, Epsilon: 0.014, Steps: 154, Food: 3\n",
      "Episode 425, Total Reward: 102.40, Epsilon: 0.014, Steps: 191, Food: 4\n",
      "Episode 426, Total Reward: 168.50, Epsilon: 0.014, Steps: 199, Food: 6\n",
      "Episode 427, Total Reward: 110.90, Epsilon: 0.014, Steps: 282, Food: 5\n",
      "Episode 428, Total Reward: 2.30, Epsilon: 0.014, Steps: 187, Food: 1\n",
      "Episode 429, Total Reward: 12.30, Epsilon: 0.013, Steps: 400, Food: 2\n",
      "Episode 430, Total Reward: -30.70, Epsilon: 0.013, Steps: 400, Food: 1\n",
      "Episode 431, Total Reward: -12.30, Epsilon: 0.013, Steps: 10, Food: 0\n",
      "Episode 432, Total Reward: -8.80, Epsilon: 0.013, Steps: 324, Food: 1\n",
      "Episode 433, Total Reward: 23.90, Epsilon: 0.013, Steps: 10, Food: 1\n",
      "Episode 434, Total Reward: -32.20, Epsilon: 0.013, Steps: 172, Food: 0\n",
      "Episode 435, Total Reward: 143.10, Epsilon: 0.013, Steps: 158, Food: 5\n",
      "Episode 436, Total Reward: -34.00, Epsilon: 0.013, Steps: 288, Food: 0\n",
      "Episode 437, Total Reward: 3.00, Epsilon: 0.012, Steps: 400, Food: 2\n",
      "Episode 438, Total Reward: 177.80, Epsilon: 0.012, Steps: 390, Food: 7\n",
      "Episode 439, Total Reward: 193.50, Epsilon: 0.012, Steps: 400, Food: 7\n",
      "Episode 440, Total Reward: 62.10, Epsilon: 0.012, Steps: 400, Food: 4\n",
      "Episode 441, Total Reward: 35.70, Epsilon: 0.012, Steps: 400, Food: 3\n",
      "Episode 442, Total Reward: -13.70, Epsilon: 0.012, Steps: 17, Food: 0\n",
      "Episode 443, Total Reward: -14.60, Epsilon: 0.012, Steps: 30, Food: 0\n",
      "Episode 444, Total Reward: -11.80, Epsilon: 0.012, Steps: 9, Food: 0\n",
      "Episode 445, Total Reward: -14.60, Epsilon: 0.011, Steps: 31, Food: 0\n",
      "Episode 446, Total Reward: 183.90, Epsilon: 0.011, Steps: 127, Food: 6\n",
      "Episode 447, Total Reward: 139.00, Epsilon: 0.011, Steps: 327, Food: 6\n",
      "Episode 448, Total Reward: 23.50, Epsilon: 0.011, Steps: 400, Food: 2\n",
      "Episode 449, Total Reward: 140.00, Epsilon: 0.011, Steps: 129, Food: 5\n",
      "Episode 450, Total Reward: 17.20, Epsilon: 0.011, Steps: 400, Food: 2\n",
      "Episode 451, Total Reward: -17.60, Epsilon: 0.011, Steps: 26, Food: 0\n",
      "Episode 452, Total Reward: 10.90, Epsilon: 0.011, Steps: 109, Food: 1\n",
      "Episode 453, Total Reward: 15.40, Epsilon: 0.011, Steps: 249, Food: 2\n",
      "Episode 454, Total Reward: 39.40, Epsilon: 0.010, Steps: 400, Food: 3\n",
      "Episode 455, Total Reward: 16.10, Epsilon: 0.010, Steps: 46, Food: 1\n",
      "Episode 456, Total Reward: 191.80, Epsilon: 0.010, Steps: 270, Food: 7\n",
      "Episode 457, Total Reward: 9.80, Epsilon: 0.010, Steps: 400, Food: 2\n",
      "Episode 458, Total Reward: -23.60, Epsilon: 0.010, Steps: 400, Food: 1\n",
      "Episode 459, Total Reward: -30.70, Epsilon: 0.010, Steps: 96, Food: 0\n",
      "Episode 460, Total Reward: 86.80, Epsilon: 0.010, Steps: 69, Food: 3\n",
      "Episode 461, Total Reward: -72.20, Epsilon: 0.010, Steps: 400, Food: 0\n",
      "Episode 462, Total Reward: -18.40, Epsilon: 0.010, Steps: 43, Food: 0\n",
      "Episode 463, Total Reward: -22.00, Epsilon: 0.010, Steps: 67, Food: 0\n",
      "Episode 464, Total Reward: -14.20, Epsilon: 0.010, Steps: 10, Food: 0\n",
      "Episode 465, Total Reward: -8.10, Epsilon: 0.010, Steps: 400, Food: 1\n",
      "Episode 466, Total Reward: -9.30, Epsilon: 0.010, Steps: 9, Food: 0\n",
      "Episode 467, Total Reward: -11.10, Epsilon: 0.010, Steps: 7, Food: 0\n",
      "Episode 468, Total Reward: 72.30, Epsilon: 0.010, Steps: 316, Food: 4\n",
      "Episode 469, Total Reward: -2.70, Epsilon: 0.010, Steps: 400, Food: 1\n",
      "Episode 470, Total Reward: 39.60, Epsilon: 0.010, Steps: 123, Food: 2\n",
      "Episode 471, Total Reward: 25.20, Epsilon: 0.010, Steps: 6, Food: 1\n",
      "Episode 472, Total Reward: -22.60, Epsilon: 0.010, Steps: 75, Food: 0\n",
      "Episode 473, Total Reward: 18.50, Epsilon: 0.010, Steps: 59, Food: 1\n",
      "Episode 474, Total Reward: 15.30, Epsilon: 0.010, Steps: 40, Food: 1\n",
      "Episode 475, Total Reward: 154.50, Epsilon: 0.010, Steps: 71, Food: 5\n",
      "Episode 476, Total Reward: 114.40, Epsilon: 0.010, Steps: 98, Food: 4\n",
      "Episode 477, Total Reward: -29.80, Epsilon: 0.010, Steps: 115, Food: 0\n",
      "Episode 478, Total Reward: -8.70, Epsilon: 0.010, Steps: 392, Food: 1\n",
      "Episode 479, Total Reward: 4.10, Epsilon: 0.010, Steps: 88, Food: 1\n",
      "Episode 480, Total Reward: -18.10, Epsilon: 0.010, Steps: 40, Food: 0\n",
      "Episode 481, Total Reward: -3.80, Epsilon: 0.010, Steps: 400, Food: 0\n",
      "Episode 482, Total Reward: -91.10, Epsilon: 0.010, Steps: 400, Food: 0\n",
      "Episode 483, Total Reward: -14.10, Epsilon: 0.010, Steps: 14, Food: 0\n",
      "Episode 484, Total Reward: -13.00, Epsilon: 0.010, Steps: 8, Food: 0\n",
      "Episode 485, Total Reward: 28.40, Epsilon: 0.010, Steps: 375, Food: 3\n",
      "Episode 486, Total Reward: 48.00, Epsilon: 0.010, Steps: 372, Food: 3\n",
      "Episode 487, Total Reward: -17.50, Epsilon: 0.010, Steps: 35, Food: 0\n",
      "Episode 488, Total Reward: 23.10, Epsilon: 0.010, Steps: 10, Food: 1\n",
      "Episode 489, Total Reward: 164.00, Epsilon: 0.010, Steps: 313, Food: 6\n",
      "Episode 490, Total Reward: -11.80, Epsilon: 0.010, Steps: 8, Food: 0\n",
      "Episode 491, Total Reward: 82.50, Epsilon: 0.010, Steps: 303, Food: 4\n",
      "Episode 492, Total Reward: -13.40, Epsilon: 0.010, Steps: 400, Food: 1\n",
      "Episode 493, Total Reward: -12.40, Epsilon: 0.010, Steps: 6, Food: 0\n",
      "Episode 494, Total Reward: 18.30, Epsilon: 0.010, Steps: 56, Food: 1\n",
      "Episode 495, Total Reward: 9.40, Epsilon: 0.010, Steps: 223, Food: 1\n",
      "Episode 496, Total Reward: -35.80, Epsilon: 0.010, Steps: 163, Food: 0\n",
      "Episode 497, Total Reward: 29.40, Epsilon: 0.010, Steps: 400, Food: 1\n",
      "Episode 498, Total Reward: 41.80, Epsilon: 0.010, Steps: 86, Food: 2\n",
      "Episode 499, Total Reward: 73.40, Epsilon: 0.010, Steps: 171, Food: 3\n",
      "Episode 500, Total Reward: -17.20, Epsilon: 0.010, Steps: 24, Food: 0\n"
     ]
    }
   ],
   "source": [
    "# Training loop for Snake Game\n",
    "env = SnakeGame(render_mode=None)\n",
    "memory = deque(maxlen=10000)\n",
    "batch_size = 64\n",
    "gamma = 0.99\n",
    "learning_rate = 1e-3\n",
    "target_update_freq = 10\n",
    "num_episodes = 500\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "state_space = np.prod(env.observation_space.shape)\n",
    "policy_net = DQN(state_space, env.action_space.n).to(device)\n",
    "target_net = DQN(state_space, env.action_space.n).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "\n",
    "optimizer = torch.optim.Adam(policy_net.parameters(), lr=learning_rate)\n",
    "replay_buffer = ExperienceBuffer(capacity=10000)\n",
    "epsilon = 1.0\n",
    "epsilon_decay = 0.990\n",
    "epsilon_min = 0.01\n",
    "max_steps_per_episode = 400\n",
    "for episode in range(num_episodes):\n",
    "    state, _ = env.reset()\n",
    "    state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0).view(1, -1)\n",
    "    total_reward = 0\n",
    "    steps = 0\n",
    "    food_collected = 0\n",
    "    done = False\n",
    "\n",
    "    while not done and steps < max_steps_per_episode:\n",
    "        if random.random() < epsilon:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                q_values = policy_net(state)\n",
    "                action = q_values.argmax().item()\n",
    "\n",
    "        next_state, reward, done, _, info = env.step(action)\n",
    "        \n",
    "        # Count food collected based on info dict (assuming 'food_collected' flag is set in env)\n",
    "        if info.get(\"food_eaten\", False):\n",
    "            food_collected += 1\n",
    "\n",
    "        next_state_tensor = torch.tensor(next_state, dtype=torch.float32, device=device).unsqueeze(0).view(1, -1)\n",
    "        replay_buffer.push(state, action, reward, next_state_tensor, done)\n",
    "        state = next_state_tensor\n",
    "        total_reward += reward\n",
    "        steps += 1\n",
    "\n",
    "        if len(replay_buffer) >= batch_size:\n",
    "            states, actions, rewards, next_states, dones = replay_buffer.sample(batch_size)\n",
    "            states = torch.cat(states).view(batch_size, -1)\n",
    "            next_states = torch.cat(next_states).view(batch_size, -1)\n",
    "            actions = torch.tensor(actions, device=device).unsqueeze(1)\n",
    "            rewards = torch.tensor(rewards, dtype=torch.float32, device=device).unsqueeze(1)\n",
    "            dones = torch.tensor(dones, dtype=torch.float32, device=device).unsqueeze(1)\n",
    "\n",
    "            curr_q_values = policy_net(states).gather(1, actions)\n",
    "            next_q_values = target_net(next_states).max(1)[0].detach().unsqueeze(1)\n",
    "            expected_q_values = rewards + gamma * next_q_values * (1 - dones)\n",
    "\n",
    "            loss = F.mse_loss(curr_q_values, expected_q_values)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Decay epsilon\n",
    "    if epsilon > epsilon_min:\n",
    "        epsilon *= epsilon_decay\n",
    "\n",
    "    # Update target network\n",
    "    if episode % target_update_freq == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "    print(f\"Episode {episode + 1}, Total Reward: {total_reward:.2f}, Epsilon: {epsilon:.3f}, Steps: {steps}, Food: {food_collected}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a0e10565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_snake_model(model, size=20, episodes=10, render=True):\n",
    "    env = SnakeGame(size=size, render_mode=\"human\" if render else None)\n",
    "    model.eval()\n",
    "\n",
    "    rewards = []\n",
    "    foods = []\n",
    "\n",
    "    for episode in range(episodes):\n",
    "        obs, _ = env.reset()\n",
    "        total_reward = 0\n",
    "        food_collected = 0\n",
    "        done = False\n",
    "        max_steps = 500\n",
    "        steps = 0\n",
    "        while not done and steps < max_steps:\n",
    "            steps += 1\n",
    "            obs_resized = F.interpolate(torch.tensor(obs, dtype=torch.float32).unsqueeze(0), size=(10, 10), mode='bilinear')\n",
    "            state = obs_resized.view(1, -1)[:, :300]\n",
    "            with torch.no_grad():\n",
    "                q_values = model(state)\n",
    "                action = torch.argmax(q_values, dim=1).item()\n",
    "\n",
    "            obs, reward, done, _, info = env.step(action)\n",
    "            total_reward += reward\n",
    "\n",
    "            # â Count food collected if info dict has that flag\n",
    "            if isinstance(info, dict) and info.get(\"food_eaten\", False):\n",
    "                food_collected += 1\n",
    "\n",
    "            if render:\n",
    "                env.render()\n",
    "\n",
    "        rewards.append(total_reward)\n",
    "        foods.append(food_collected)\n",
    "        print(f\"Episode {episode + 1}: Reward = {total_reward}, Food Collected = {food_collected}\")\n",
    "\n",
    "    env.close()\n",
    "    avg_reward = sum(rewards) / episodes\n",
    "    avg_food = sum(foods) / episodes\n",
    "\n",
    "    print(f\"\\nAverage reward over {episodes} episodes: {avg_reward:.2f}\")\n",
    "    print(f\"Average food collected: {avg_food:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1a7eb581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Reward = -1.9999999999999998, Food Collected = 0\n",
      "Episode 2: Reward = 54.800000000000026, Food Collected = 2\n",
      "Episode 3: Reward = 18.799999999999997, Food Collected = 1\n",
      "Episode 4: Reward = 35.09999999999995, Food Collected = 3\n",
      "Episode 5: Reward = -19.3, Food Collected = 0\n",
      "Episode 6: Reward = -23.500000000000007, Food Collected = 0\n",
      "Episode 7: Reward = -18.700000000000003, Food Collected = 0\n",
      "Episode 8: Reward = -16.199999999999996, Food Collected = 0\n",
      "Episode 9: Reward = -23.699999999999996, Food Collected = 0\n",
      "Episode 10: Reward = 33.89999999999997, Food Collected = 1\n",
      "\n",
      "Average reward over 10 episodes: 3.92\n",
      "Average food collected: 0.70\n"
     ]
    }
   ],
   "source": [
    "# TODO: Run evaluation for Snake Game here\n",
    "evaluate_snake_model(policy_net, size=20, episodes=10, render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4224fabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChaseEscapeEnv(gym.Env):\n",
    "    metadata = {\"render_modes\": [\"human\"], \"render_fps\": 30}\n",
    "\n",
    "    def __init__(self, render_mode=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dt = 0.1\n",
    "        self.max_speed = 0.4\n",
    "        self.agent_radius = 0.05\n",
    "        self.target_radius = 0.05\n",
    "        self.chaser_radius = 0.05\n",
    "        self.chaser_speed = 0.03\n",
    "\n",
    "        self.action_space = gym.spaces.MultiDiscrete([3, 3])  # actions in {0,1,2} map to [-1,0,1]\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            low=-1,\n",
    "            high=1,\n",
    "            shape=(8,),\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "\n",
    "        self.render_mode = render_mode\n",
    "        self.screen_size = 500\n",
    "        self.np_random = None\n",
    "\n",
    "        if render_mode == \"human\":\n",
    "            pygame.init()\n",
    "            self.screen = pygame.display.set_mode((self.screen_size, self.screen_size))\n",
    "            self.clock = pygame.time.Clock()\n",
    "\n",
    "    def sample_pos(self, far_from=None, min_dist=0.5):\n",
    "        while True:\n",
    "            pos = self.np_random.uniform(low=-0.8, high=0.8, size=(2,))\n",
    "            if far_from is None or np.linalg.norm(pos - far_from) >= min_dist:\n",
    "                return pos\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "\n",
    "        self.agent_pos = self.sample_pos()\n",
    "        self.agent_vel = np.zeros(2, dtype=np.float32)\n",
    "        self.target_pos = self.sample_pos(far_from=self.agent_pos, min_dist=0.5)\n",
    "        self.chaser_pos = self.sample_pos(far_from=self.agent_pos, min_dist=0.7)\n",
    "\n",
    "        return self._get_obs(), {}\n",
    "\n",
    "    def _get_obs(self):\n",
    "        # TODO: Decide how to pass the state (don't use pixel values)\n",
    "        agent_x, agent_y = self.agent_pos\n",
    "        agent_vx, agent_vy = self.agent_vel\n",
    "        target_x, target_y = self.target_pos\n",
    "        chaser_x, chaser_y = self.chaser_pos\n",
    "        return np.array([agent_x, agent_y, agent_vx, agent_vy, target_x, target_y, chaser_x, chaser_y], dtype=np.float32)\n",
    "\n",
    "\n",
    "    def _get_info(self):\n",
    "        return {}\n",
    "\n",
    "    def step(self, action):\n",
    "        # TODO: Add reward scheme\n",
    "        # 1) Try to make the agent stay within bounds\n",
    "        # 2) The agent shouldn't idle around\n",
    "        # 3) The agent should go for the reward\n",
    "        # 4) The agent should avoid the chaser\n",
    "        reward = 0.0\n",
    "        prev_dist_to_target = np.linalg.norm(self.agent_pos - self.target_pos)\n",
    "        accel = (np.array(action) - 1) * 0.1\n",
    "        self.agent_vel += accel\n",
    "        self.agent_vel = np.clip(self.agent_vel, -self.max_speed, self.max_speed)\n",
    "        # Save intended new position before clipping\n",
    "        new_pos = self.agent_pos.copy()\n",
    "        new_pos += self.agent_vel * self.dt\n",
    "\n",
    "        # Penalize if new position goes out of bounds\n",
    "        if np.any(new_pos < -1) or np.any(new_pos > 1):\n",
    "            reward -= 0.1\n",
    "\n",
    "        # Apply clipping to stay within bounds\n",
    "        self.agent_pos = np.clip(new_pos, -1, 1)\n",
    "\n",
    "        if np.linalg.norm(self.agent_vel) < 0.01:\n",
    "            reward -= 0.05  # or stronger penalty if needed\n",
    "\n",
    "        direction = self.agent_pos - self.chaser_pos\n",
    "        norm = np.linalg.norm(direction)\n",
    "        if norm > 1e-5:\n",
    "            self.chaser_pos += self.chaser_speed * direction / norm\n",
    "\n",
    "        dist_to_target = np.linalg.norm(self.agent_pos - self.target_pos)\n",
    "        dist_to_chaser = np.linalg.norm(self.agent_pos - self.chaser_pos)\n",
    "\n",
    "        if dist_to_chaser < 0.5:\n",
    "            if norm > 1e-5:\n",
    "                projected_chaser_pos = self.chaser_pos - self.chaser_speed * direction / norm\n",
    "                prev_dist_to_chaser = np.linalg.norm(self.agent_pos - projected_chaser_pos)\n",
    "            else:\n",
    "                prev_dist_to_chaser = dist_to_chaser\n",
    "\n",
    "            delta_chaser = prev_dist_to_chaser - dist_to_chaser\n",
    "            reward += delta_chaser * 0.3  # penalize moving toward chaser only when close\n",
    "\n",
    "        delta = prev_dist_to_target - dist_to_target\n",
    "        reward += delta * 0.5  # scale it to keep values small\n",
    "\n",
    "\n",
    "        terminated = False\n",
    "\n",
    "        info = {}\n",
    "        if dist_to_target < self.agent_radius + self.target_radius:\n",
    "            reward += 10.0\n",
    "            self.target_pos = self.sample_pos(far_from=self.agent_pos, min_dist=0.5)\n",
    "            info[\"target_captured\"] = True\n",
    "\n",
    "        if dist_to_target < 0.3:\n",
    "            reward += 0.1\n",
    "\n",
    "        if dist_to_chaser < self.agent_radius + self.chaser_radius:\n",
    "            reward -= 3.0\n",
    "            terminated = True\n",
    "            info[\"caught_by_chaser\"] = True\n",
    "\n",
    "        return self._get_obs(), reward, terminated, False, info\n",
    "\n",
    "\n",
    "    def render(self):\n",
    "        if self.render_mode != \"human\":\n",
    "            return\n",
    "\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                self.close()\n",
    "\n",
    "        self.screen.fill((255, 255, 255))\n",
    "\n",
    "        def to_screen(p):\n",
    "            x = int((p[0] + 1) / 2 * self.screen_size)\n",
    "            y = int((1 - (p[1] + 1) / 2) * self.screen_size)\n",
    "            return x, y\n",
    "\n",
    "        pygame.draw.circle(self.screen, (0, 255, 0), to_screen(self.target_pos), int(self.target_radius * self.screen_size))\n",
    "        pygame.draw.circle(self.screen, (0, 0, 255), to_screen(self.agent_pos), int(self.agent_radius * self.screen_size))\n",
    "        pygame.draw.circle(self.screen, (255, 0, 0), to_screen(self.chaser_pos), int(self.chaser_radius * self.screen_size))\n",
    "\n",
    "        pygame.display.flip()\n",
    "        self.clock.tick(self.metadata[\"render_fps\"])\n",
    "\n",
    "    def close(self):\n",
    "        if self.render_mode == \"human\":\n",
    "            pygame.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9eca1390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 000 | Reward: -2.22 | Steps: 19 | Captures: 0 | Caught: True\n",
      "Ep 001 | Reward: -4.83 | Steps: 49 | Captures: 0 | Caught: True\n",
      "Ep 002 | Reward: -2.86 | Steps: 73 | Captures: 0 | Caught: True\n",
      "Ep 003 | Reward: -6.13 | Steps: 48 | Captures: 0 | Caught: True\n",
      "Ep 004 | Reward: -7.15 | Steps: 50 | Captures: 0 | Caught: True\n",
      "Ep 005 | Reward: -6.38 | Steps: 46 | Captures: 0 | Caught: True\n",
      "Ep 006 | Reward: -5.44 | Steps: 48 | Captures: 0 | Caught: True\n",
      "Ep 007 | Reward: -3.00 | Steps: 14 | Captures: 0 | Caught: True\n",
      "Ep 008 | Reward: -3.57 | Steps: 33 | Captures: 0 | Caught: True\n",
      "Ep 009 | Reward: -2.88 | Steps: 17 | Captures: 0 | Caught: True\n",
      "Ep 010 | Reward: -7.72 | Steps: 67 | Captures: 0 | Caught: True\n",
      "Ep 011 | Reward: -3.03 | Steps: 13 | Captures: 0 | Caught: True\n",
      "Ep 012 | Reward: -6.91 | Steps: 69 | Captures: 0 | Caught: True\n",
      "Ep 013 | Reward: -7.60 | Steps: 80 | Captures: 0 | Caught: True\n",
      "Ep 014 | Reward: -2.77 | Steps: 18 | Captures: 0 | Caught: True\n",
      "Ep 015 | Reward: -2.86 | Steps: 27 | Captures: 0 | Caught: True\n",
      "Ep 016 | Reward: -2.74 | Steps: 31 | Captures: 0 | Caught: True\n",
      "Ep 017 | Reward: -6.11 | Steps: 78 | Captures: 0 | Caught: True\n",
      "Ep 018 | Reward: -6.60 | Steps: 49 | Captures: 0 | Caught: True\n",
      "Ep 019 | Reward: -2.80 | Steps: 46 | Captures: 0 | Caught: True\n",
      "Ep 020 | Reward: -5.48 | Steps: 50 | Captures: 0 | Caught: True\n",
      "Ep 021 | Reward: -3.88 | Steps: 24 | Captures: 0 | Caught: True\n",
      "Ep 022 | Reward: -2.79 | Steps: 20 | Captures: 0 | Caught: True\n",
      "Ep 023 | Reward: 8.61 | Steps: 64 | Captures: 1 | Caught: True\n",
      "Ep 024 | Reward: -3.07 | Steps: 37 | Captures: 0 | Caught: True\n",
      "Ep 025 | Reward: -6.96 | Steps: 52 | Captures: 0 | Caught: True\n",
      "Ep 026 | Reward: -2.81 | Steps: 32 | Captures: 0 | Caught: True\n",
      "Ep 027 | Reward: -3.08 | Steps: 19 | Captures: 0 | Caught: True\n",
      "Ep 028 | Reward: -9.73 | Steps: 185 | Captures: 0 | Caught: True\n",
      "Ep 029 | Reward: -6.56 | Steps: 46 | Captures: 0 | Caught: True\n",
      "Ep 030 | Reward: -2.81 | Steps: 26 | Captures: 0 | Caught: True\n",
      "Ep 031 | Reward: -8.44 | Steps: 67 | Captures: 0 | Caught: True\n",
      "Ep 032 | Reward: -7.19 | Steps: 50 | Captures: 0 | Caught: True\n",
      "Ep 033 | Reward: -6.18 | Steps: 59 | Captures: 0 | Caught: True\n",
      "Ep 034 | Reward: -2.69 | Steps: 59 | Captures: 0 | Caught: True\n",
      "Ep 035 | Reward: -6.21 | Steps: 78 | Captures: 0 | Caught: True\n",
      "Ep 036 | Reward: -3.59 | Steps: 69 | Captures: 0 | Caught: True\n",
      "Ep 037 | Reward: -3.89 | Steps: 46 | Captures: 0 | Caught: True\n",
      "Ep 038 | Reward: -3.02 | Steps: 35 | Captures: 0 | Caught: True\n",
      "Ep 039 | Reward: -2.77 | Steps: 15 | Captures: 0 | Caught: True\n",
      "Ep 040 | Reward: -5.81 | Steps: 39 | Captures: 0 | Caught: True\n",
      "Ep 041 | Reward: -2.85 | Steps: 37 | Captures: 0 | Caught: True\n",
      "Ep 042 | Reward: -4.51 | Steps: 48 | Captures: 0 | Caught: True\n",
      "Ep 043 | Reward: -3.15 | Steps: 37 | Captures: 0 | Caught: True\n",
      "Ep 044 | Reward: -5.45 | Steps: 57 | Captures: 0 | Caught: True\n",
      "Ep 045 | Reward: -8.81 | Steps: 70 | Captures: 0 | Caught: True\n",
      "Ep 046 | Reward: -4.88 | Steps: 58 | Captures: 0 | Caught: True\n",
      "Ep 047 | Reward: -7.59 | Steps: 83 | Captures: 0 | Caught: True\n",
      "Ep 048 | Reward: -5.81 | Steps: 63 | Captures: 0 | Caught: True\n",
      "Ep 049 | Reward: -2.90 | Steps: 19 | Captures: 0 | Caught: True\n",
      "Ep 050 | Reward: -7.25 | Steps: 75 | Captures: 0 | Caught: True\n",
      "Ep 051 | Reward: -6.30 | Steps: 62 | Captures: 0 | Caught: True\n",
      "Ep 052 | Reward: -3.53 | Steps: 51 | Captures: 0 | Caught: True\n",
      "Ep 053 | Reward: -6.44 | Steps: 50 | Captures: 0 | Caught: True\n",
      "Ep 054 | Reward: -2.73 | Steps: 48 | Captures: 0 | Caught: True\n",
      "Ep 055 | Reward: -3.15 | Steps: 58 | Captures: 0 | Caught: True\n",
      "Ep 056 | Reward: -6.52 | Steps: 77 | Captures: 0 | Caught: True\n",
      "Ep 057 | Reward: -3.84 | Steps: 50 | Captures: 0 | Caught: True\n",
      "Ep 058 | Reward: -6.14 | Steps: 58 | Captures: 0 | Caught: True\n",
      "Ep 059 | Reward: -8.00 | Steps: 68 | Captures: 0 | Caught: True\n",
      "Ep 060 | Reward: 8.19 | Steps: 37 | Captures: 1 | Caught: True\n",
      "Ep 061 | Reward: -2.56 | Steps: 62 | Captures: 0 | Caught: True\n",
      "Ep 062 | Reward: -2.97 | Steps: 19 | Captures: 0 | Caught: True\n",
      "Ep 063 | Reward: -2.78 | Steps: 23 | Captures: 0 | Caught: True\n",
      "Ep 064 | Reward: -4.74 | Steps: 59 | Captures: 0 | Caught: True\n",
      "Ep 065 | Reward: -2.51 | Steps: 11 | Captures: 0 | Caught: True\n",
      "Ep 066 | Reward: -4.48 | Steps: 72 | Captures: 0 | Caught: True\n",
      "Ep 067 | Reward: -5.68 | Steps: 58 | Captures: 0 | Caught: True\n",
      "Ep 068 | Reward: -2.78 | Steps: 20 | Captures: 0 | Caught: True\n",
      "Ep 069 | Reward: -6.97 | Steps: 70 | Captures: 0 | Caught: True\n",
      "Ep 070 | Reward: -6.36 | Steps: 119 | Captures: 0 | Caught: True\n",
      "Ep 071 | Reward: -6.24 | Steps: 42 | Captures: 0 | Caught: True\n",
      "Ep 072 | Reward: -3.78 | Steps: 26 | Captures: 0 | Caught: True\n",
      "Ep 073 | Reward: -5.56 | Steps: 43 | Captures: 0 | Caught: True\n",
      "Ep 074 | Reward: -3.07 | Steps: 12 | Captures: 0 | Caught: True\n",
      "Ep 075 | Reward: -2.82 | Steps: 10 | Captures: 0 | Caught: True\n",
      "Ep 076 | Reward: -6.64 | Steps: 60 | Captures: 0 | Caught: True\n",
      "Ep 077 | Reward: -4.21 | Steps: 45 | Captures: 0 | Caught: True\n",
      "Ep 078 | Reward: -5.73 | Steps: 61 | Captures: 0 | Caught: True\n",
      "Ep 079 | Reward: -2.72 | Steps: 13 | Captures: 0 | Caught: True\n",
      "Ep 080 | Reward: -6.07 | Steps: 64 | Captures: 0 | Caught: True\n",
      "Ep 081 | Reward: -2.90 | Steps: 16 | Captures: 0 | Caught: True\n",
      "Ep 082 | Reward: -3.82 | Steps: 72 | Captures: 0 | Caught: True\n",
      "Ep 083 | Reward: -2.65 | Steps: 24 | Captures: 0 | Caught: True\n",
      "Ep 084 | Reward: -4.43 | Steps: 78 | Captures: 0 | Caught: True\n",
      "Ep 085 | Reward: -2.97 | Steps: 36 | Captures: 0 | Caught: True\n",
      "Ep 086 | Reward: -4.04 | Steps: 37 | Captures: 0 | Caught: True\n",
      "Ep 087 | Reward: -4.62 | Steps: 54 | Captures: 0 | Caught: True\n",
      "Ep 088 | Reward: -3.88 | Steps: 36 | Captures: 0 | Caught: True\n",
      "Ep 089 | Reward: -9.47 | Steps: 115 | Captures: 0 | Caught: True\n",
      "Ep 090 | Reward: -1.32 | Steps: 41 | Captures: 0 | Caught: True\n",
      "Ep 091 | Reward: 9.51 | Steps: 77 | Captures: 1 | Caught: True\n",
      "Ep 092 | Reward: -4.09 | Steps: 34 | Captures: 0 | Caught: True\n",
      "Ep 093 | Reward: -4.85 | Steps: 58 | Captures: 0 | Caught: True\n",
      "Ep 094 | Reward: -7.80 | Steps: 60 | Captures: 0 | Caught: True\n",
      "Ep 095 | Reward: -2.78 | Steps: 28 | Captures: 0 | Caught: True\n",
      "Ep 096 | Reward: -7.04 | Steps: 90 | Captures: 0 | Caught: True\n",
      "Ep 097 | Reward: -4.06 | Steps: 29 | Captures: 0 | Caught: True\n",
      "Ep 098 | Reward: -7.43 | Steps: 121 | Captures: 0 | Caught: True\n",
      "Ep 099 | Reward: -3.19 | Steps: 26 | Captures: 0 | Caught: True\n",
      "Ep 100 | Reward: -6.49 | Steps: 80 | Captures: 0 | Caught: True\n",
      "Ep 101 | Reward: -5.68 | Steps: 61 | Captures: 0 | Caught: True\n",
      "Ep 102 | Reward: -2.83 | Steps: 17 | Captures: 0 | Caught: True\n",
      "Ep 103 | Reward: -5.86 | Steps: 53 | Captures: 0 | Caught: True\n",
      "Ep 104 | Reward: -4.64 | Steps: 49 | Captures: 0 | Caught: True\n",
      "Ep 105 | Reward: -4.04 | Steps: 54 | Captures: 0 | Caught: True\n",
      "Ep 106 | Reward: -2.78 | Steps: 12 | Captures: 0 | Caught: True\n",
      "Ep 107 | Reward: -7.07 | Steps: 121 | Captures: 0 | Caught: True\n",
      "Ep 108 | Reward: -10.48 | Steps: 87 | Captures: 0 | Caught: True\n",
      "Ep 109 | Reward: 4.46 | Steps: 72 | Captures: 1 | Caught: True\n",
      "Ep 110 | Reward: -7.11 | Steps: 58 | Captures: 0 | Caught: True\n",
      "Ep 111 | Reward: -2.74 | Steps: 24 | Captures: 0 | Caught: True\n",
      "Ep 112 | Reward: -10.45 | Steps: 90 | Captures: 0 | Caught: True\n",
      "Ep 113 | Reward: -2.89 | Steps: 18 | Captures: 0 | Caught: True\n",
      "Ep 114 | Reward: -2.91 | Steps: 18 | Captures: 0 | Caught: True\n",
      "Ep 115 | Reward: -9.95 | Steps: 137 | Captures: 0 | Caught: True\n",
      "Ep 116 | Reward: 2.67 | Steps: 109 | Captures: 1 | Caught: True\n",
      "Ep 117 | Reward: -2.71 | Steps: 18 | Captures: 0 | Caught: True\n",
      "Ep 118 | Reward: -2.33 | Steps: 72 | Captures: 0 | Caught: True\n",
      "Ep 119 | Reward: -6.07 | Steps: 90 | Captures: 0 | Caught: True\n",
      "Ep 120 | Reward: -8.45 | Steps: 121 | Captures: 0 | Caught: True\n",
      "Ep 121 | Reward: -6.87 | Steps: 128 | Captures: 0 | Caught: True\n",
      "Ep 122 | Reward: -5.19 | Steps: 53 | Captures: 0 | Caught: True\n",
      "Ep 123 | Reward: -7.89 | Steps: 63 | Captures: 0 | Caught: True\n",
      "Ep 124 | Reward: -5.47 | Steps: 66 | Captures: 0 | Caught: True\n",
      "Ep 125 | Reward: -5.87 | Steps: 115 | Captures: 0 | Caught: True\n",
      "Ep 126 | Reward: -7.32 | Steps: 72 | Captures: 0 | Caught: True\n",
      "Ep 127 | Reward: -14.20 | Steps: 177 | Captures: 0 | Caught: True\n",
      "Ep 128 | Reward: -5.65 | Steps: 45 | Captures: 0 | Caught: True\n",
      "Ep 129 | Reward: -3.06 | Steps: 41 | Captures: 0 | Caught: True\n",
      "Ep 130 | Reward: -5.92 | Steps: 66 | Captures: 0 | Caught: True\n",
      "Ep 131 | Reward: -3.70 | Steps: 48 | Captures: 0 | Caught: True\n",
      "Ep 132 | Reward: -2.88 | Steps: 29 | Captures: 0 | Caught: True\n",
      "Ep 133 | Reward: -3.74 | Steps: 22 | Captures: 0 | Caught: True\n",
      "Ep 134 | Reward: -3.08 | Steps: 19 | Captures: 0 | Caught: True\n",
      "Ep 135 | Reward: -6.90 | Steps: 60 | Captures: 0 | Caught: True\n",
      "Ep 136 | Reward: -7.20 | Steps: 69 | Captures: 0 | Caught: True\n",
      "Ep 137 | Reward: -3.98 | Steps: 36 | Captures: 0 | Caught: True\n",
      "Ep 138 | Reward: -7.82 | Steps: 130 | Captures: 0 | Caught: True\n",
      "Ep 139 | Reward: -2.61 | Steps: 74 | Captures: 0 | Caught: True\n",
      "Ep 140 | Reward: -4.97 | Steps: 57 | Captures: 0 | Caught: True\n",
      "Ep 141 | Reward: -5.25 | Steps: 57 | Captures: 0 | Caught: True\n",
      "Ep 142 | Reward: -5.40 | Steps: 48 | Captures: 0 | Caught: True\n",
      "Ep 143 | Reward: -3.06 | Steps: 17 | Captures: 0 | Caught: True\n",
      "Ep 144 | Reward: -9.06 | Steps: 74 | Captures: 0 | Caught: True\n",
      "Ep 145 | Reward: -10.02 | Steps: 122 | Captures: 0 | Caught: True\n",
      "Ep 146 | Reward: -7.34 | Steps: 53 | Captures: 0 | Caught: True\n",
      "Ep 147 | Reward: -6.67 | Steps: 68 | Captures: 0 | Caught: True\n",
      "Ep 148 | Reward: -3.97 | Steps: 62 | Captures: 0 | Caught: True\n",
      "Ep 149 | Reward: -13.58 | Steps: 141 | Captures: 0 | Caught: True\n",
      "Ep 150 | Reward: -2.82 | Steps: 30 | Captures: 0 | Caught: True\n",
      "Ep 151 | Reward: -6.48 | Steps: 53 | Captures: 0 | Caught: True\n",
      "Ep 152 | Reward: -6.81 | Steps: 67 | Captures: 0 | Caught: True\n",
      "Ep 153 | Reward: -1.40 | Steps: 45 | Captures: 0 | Caught: True\n",
      "Ep 154 | Reward: -5.70 | Steps: 48 | Captures: 0 | Caught: True\n",
      "Ep 155 | Reward: -3.12 | Steps: 16 | Captures: 0 | Caught: True\n",
      "Ep 156 | Reward: -5.25 | Steps: 44 | Captures: 0 | Caught: True\n",
      "Ep 157 | Reward: -8.17 | Steps: 111 | Captures: 0 | Caught: True\n",
      "Ep 158 | Reward: -7.30 | Steps: 60 | Captures: 0 | Caught: True\n",
      "Ep 159 | Reward: -2.98 | Steps: 29 | Captures: 0 | Caught: True\n",
      "Ep 160 | Reward: -5.77 | Steps: 52 | Captures: 0 | Caught: True\n",
      "Ep 161 | Reward: -2.71 | Steps: 33 | Captures: 0 | Caught: True\n",
      "Ep 162 | Reward: -4.41 | Steps: 47 | Captures: 0 | Caught: True\n",
      "Ep 163 | Reward: -6.73 | Steps: 53 | Captures: 0 | Caught: True\n",
      "Ep 164 | Reward: -12.11 | Steps: 125 | Captures: 0 | Caught: True\n",
      "Ep 165 | Reward: -7.09 | Steps: 68 | Captures: 0 | Caught: True\n",
      "Ep 166 | Reward: -2.79 | Steps: 22 | Captures: 0 | Caught: True\n",
      "Ep 167 | Reward: -7.36 | Steps: 64 | Captures: 0 | Caught: True\n",
      "Ep 168 | Reward: -3.43 | Steps: 50 | Captures: 0 | Caught: True\n",
      "Ep 169 | Reward: -7.50 | Steps: 93 | Captures: 0 | Caught: True\n",
      "Ep 170 | Reward: -6.85 | Steps: 71 | Captures: 0 | Caught: True\n",
      "Ep 171 | Reward: -7.33 | Steps: 106 | Captures: 0 | Caught: True\n",
      "Ep 172 | Reward: -8.36 | Steps: 132 | Captures: 0 | Caught: True\n",
      "Ep 173 | Reward: -5.49 | Steps: 35 | Captures: 0 | Caught: True\n",
      "Ep 174 | Reward: -3.00 | Steps: 14 | Captures: 0 | Caught: True\n",
      "Ep 175 | Reward: -8.29 | Steps: 77 | Captures: 0 | Caught: True\n",
      "Ep 176 | Reward: -4.38 | Steps: 58 | Captures: 0 | Caught: True\n",
      "Ep 177 | Reward: -4.47 | Steps: 158 | Captures: 0 | Caught: True\n",
      "Ep 178 | Reward: -5.08 | Steps: 71 | Captures: 0 | Caught: True\n",
      "Ep 179 | Reward: -5.44 | Steps: 60 | Captures: 0 | Caught: True\n",
      "Ep 180 | Reward: -7.27 | Steps: 90 | Captures: 0 | Caught: True\n",
      "Ep 181 | Reward: 5.75 | Steps: 130 | Captures: 1 | Caught: True\n",
      "Ep 182 | Reward: -2.93 | Steps: 21 | Captures: 0 | Caught: True\n",
      "Ep 183 | Reward: -2.61 | Steps: 22 | Captures: 0 | Caught: True\n",
      "Ep 184 | Reward: -6.37 | Steps: 77 | Captures: 0 | Caught: True\n",
      "Ep 185 | Reward: -6.24 | Steps: 99 | Captures: 0 | Caught: True\n",
      "Ep 186 | Reward: -14.81 | Steps: 134 | Captures: 0 | Caught: True\n",
      "Ep 187 | Reward: -6.23 | Steps: 56 | Captures: 0 | Caught: True\n",
      "Ep 188 | Reward: -7.71 | Steps: 83 | Captures: 0 | Caught: True\n",
      "Ep 189 | Reward: -4.93 | Steps: 65 | Captures: 0 | Caught: True\n",
      "Ep 190 | Reward: -9.53 | Steps: 165 | Captures: 0 | Caught: True\n",
      "Ep 191 | Reward: -1.90 | Steps: 93 | Captures: 0 | Caught: True\n",
      "Ep 192 | Reward: -5.21 | Steps: 144 | Captures: 0 | Caught: True\n",
      "Ep 193 | Reward: -3.33 | Steps: 59 | Captures: 0 | Caught: True\n",
      "Ep 194 | Reward: -6.50 | Steps: 72 | Captures: 0 | Caught: True\n",
      "Ep 195 | Reward: -4.28 | Steps: 54 | Captures: 0 | Caught: True\n",
      "Ep 196 | Reward: -5.17 | Steps: 42 | Captures: 0 | Caught: True\n",
      "Ep 197 | Reward: -6.96 | Steps: 62 | Captures: 0 | Caught: True\n",
      "Ep 198 | Reward: -7.18 | Steps: 50 | Captures: 0 | Caught: True\n",
      "Ep 199 | Reward: 3.98 | Steps: 161 | Captures: 1 | Caught: True\n",
      "Ep 200 | Reward: -6.22 | Steps: 66 | Captures: 0 | Caught: True\n",
      "Ep 201 | Reward: -3.82 | Steps: 46 | Captures: 0 | Caught: True\n",
      "Ep 202 | Reward: -5.57 | Steps: 57 | Captures: 0 | Caught: True\n",
      "Ep 203 | Reward: -3.20 | Steps: 32 | Captures: 0 | Caught: True\n",
      "Ep 204 | Reward: 7.12 | Steps: 62 | Captures: 1 | Caught: True\n",
      "Ep 205 | Reward: -2.56 | Steps: 30 | Captures: 0 | Caught: True\n",
      "Ep 206 | Reward: -8.44 | Steps: 64 | Captures: 0 | Caught: True\n",
      "Ep 207 | Reward: -2.39 | Steps: 31 | Captures: 0 | Caught: True\n",
      "Ep 208 | Reward: -5.83 | Steps: 55 | Captures: 0 | Caught: True\n",
      "Ep 209 | Reward: -2.72 | Steps: 344 | Captures: 0 | Caught: True\n",
      "Ep 210 | Reward: 12.51 | Steps: 160 | Captures: 2 | Caught: True\n",
      "Ep 211 | Reward: -2.76 | Steps: 12 | Captures: 0 | Caught: True\n",
      "Ep 212 | Reward: -9.49 | Steps: 88 | Captures: 0 | Caught: True\n",
      "Ep 213 | Reward: -6.07 | Steps: 63 | Captures: 0 | Caught: True\n",
      "Ep 214 | Reward: 8.03 | Steps: 24 | Captures: 1 | Caught: True\n",
      "Ep 215 | Reward: -9.74 | Steps: 107 | Captures: 0 | Caught: True\n",
      "Ep 216 | Reward: -8.81 | Steps: 63 | Captures: 0 | Caught: True\n",
      "Ep 217 | Reward: -9.07 | Steps: 168 | Captures: 0 | Caught: True\n",
      "Ep 218 | Reward: -3.08 | Steps: 35 | Captures: 0 | Caught: True\n",
      "Ep 219 | Reward: -2.84 | Steps: 15 | Captures: 0 | Caught: True\n",
      "Ep 220 | Reward: -3.12 | Steps: 28 | Captures: 0 | Caught: True\n",
      "Ep 221 | Reward: -11.63 | Steps: 188 | Captures: 0 | Caught: True\n",
      "Ep 222 | Reward: -6.57 | Steps: 114 | Captures: 0 | Caught: True\n",
      "Ep 223 | Reward: 2.84 | Steps: 184 | Captures: 1 | Caught: True\n",
      "Ep 224 | Reward: -7.04 | Steps: 56 | Captures: 0 | Caught: True\n",
      "Ep 225 | Reward: 2.86 | Steps: 190 | Captures: 1 | Caught: True\n",
      "Ep 226 | Reward: -7.57 | Steps: 66 | Captures: 0 | Caught: True\n",
      "Ep 227 | Reward: -5.11 | Steps: 55 | Captures: 0 | Caught: True\n",
      "Ep 228 | Reward: -5.39 | Steps: 62 | Captures: 0 | Caught: True\n",
      "Ep 229 | Reward: -8.31 | Steps: 132 | Captures: 0 | Caught: True\n",
      "Ep 230 | Reward: -2.80 | Steps: 32 | Captures: 0 | Caught: True\n",
      "Ep 231 | Reward: -6.02 | Steps: 58 | Captures: 0 | Caught: True\n",
      "Ep 232 | Reward: -5.88 | Steps: 79 | Captures: 0 | Caught: True\n",
      "Ep 233 | Reward: -3.28 | Steps: 62 | Captures: 0 | Caught: True\n",
      "Ep 234 | Reward: -6.50 | Steps: 65 | Captures: 0 | Caught: True\n",
      "Ep 235 | Reward: -4.41 | Steps: 146 | Captures: 0 | Caught: True\n",
      "Ep 236 | Reward: -2.89 | Steps: 29 | Captures: 0 | Caught: True\n",
      "Ep 237 | Reward: 6.99 | Steps: 40 | Captures: 1 | Caught: True\n",
      "Ep 238 | Reward: -5.93 | Steps: 61 | Captures: 0 | Caught: True\n",
      "Ep 239 | Reward: 1.94 | Steps: 336 | Captures: 1 | Caught: True\n",
      "Ep 240 | Reward: -5.00 | Steps: 41 | Captures: 0 | Caught: True\n",
      "Ep 241 | Reward: -5.12 | Steps: 59 | Captures: 0 | Caught: True\n",
      "Ep 242 | Reward: -6.39 | Steps: 470 | Captures: 0 | Caught: True\n",
      "Ep 243 | Reward: -13.96 | Steps: 419 | Captures: 0 | Caught: True\n",
      "Ep 244 | Reward: -3.98 | Steps: 118 | Captures: 0 | Caught: True\n",
      "Ep 245 | Reward: -8.16 | Steps: 70 | Captures: 0 | Caught: True\n",
      "Ep 246 | Reward: -2.56 | Steps: 73 | Captures: 0 | Caught: True\n",
      "Ep 247 | Reward: -4.07 | Steps: 42 | Captures: 0 | Caught: True\n",
      "Ep 248 | Reward: -11.30 | Steps: 261 | Captures: 0 | Caught: True\n",
      "Ep 249 | Reward: -2.83 | Steps: 17 | Captures: 0 | Caught: True\n",
      "Ep 250 | Reward: -6.63 | Steps: 62 | Captures: 0 | Caught: True\n",
      "Ep 251 | Reward: -6.80 | Steps: 76 | Captures: 0 | Caught: True\n",
      "Ep 252 | Reward: -4.23 | Steps: 67 | Captures: 0 | Caught: True\n",
      "Ep 253 | Reward: -11.09 | Steps: 94 | Captures: 0 | Caught: True\n",
      "Ep 254 | Reward: -2.74 | Steps: 12 | Captures: 0 | Caught: True\n",
      "Ep 255 | Reward: -9.31 | Steps: 184 | Captures: 0 | Caught: True\n",
      "Ep 256 | Reward: 16.21 | Steps: 150 | Captures: 2 | Caught: True\n",
      "Ep 257 | Reward: -16.40 | Steps: 157 | Captures: 0 | Caught: True\n",
      "Ep 258 | Reward: -3.18 | Steps: 30 | Captures: 0 | Caught: True\n",
      "Ep 259 | Reward: 8.15 | Steps: 32 | Captures: 1 | Caught: True\n",
      "Ep 260 | Reward: -4.77 | Steps: 42 | Captures: 0 | Caught: True\n",
      "Ep 261 | Reward: -5.52 | Steps: 64 | Captures: 0 | Caught: True\n",
      "Ep 262 | Reward: -3.91 | Steps: 76 | Captures: 0 | Caught: True\n",
      "Ep 263 | Reward: -5.44 | Steps: 76 | Captures: 0 | Caught: True\n",
      "Ep 264 | Reward: -3.51 | Steps: 30 | Captures: 0 | Caught: True\n",
      "Ep 265 | Reward: 2.91 | Steps: 197 | Captures: 1 | Caught: True\n",
      "Ep 266 | Reward: -5.37 | Steps: 44 | Captures: 0 | Caught: True\n",
      "Ep 267 | Reward: -7.34 | Steps: 77 | Captures: 0 | Caught: True\n",
      "Ep 268 | Reward: -2.82 | Steps: 49 | Captures: 0 | Caught: True\n",
      "Ep 269 | Reward: -5.02 | Steps: 73 | Captures: 0 | Caught: True\n",
      "Ep 270 | Reward: 4.44 | Steps: 64 | Captures: 1 | Caught: True\n",
      "Ep 271 | Reward: -2.96 | Steps: 15 | Captures: 0 | Caught: True\n",
      "Ep 272 | Reward: -9.35 | Steps: 102 | Captures: 0 | Caught: True\n",
      "Ep 273 | Reward: -5.09 | Steps: 57 | Captures: 0 | Caught: True\n",
      "Ep 274 | Reward: -3.29 | Steps: 70 | Captures: 0 | Caught: True\n",
      "Ep 275 | Reward: -5.92 | Steps: 166 | Captures: 0 | Caught: True\n",
      "Ep 276 | Reward: -2.74 | Steps: 16 | Captures: 0 | Caught: True\n",
      "Ep 277 | Reward: -9.76 | Steps: 110 | Captures: 0 | Caught: True\n",
      "Ep 278 | Reward: -7.36 | Steps: 89 | Captures: 0 | Caught: True\n",
      "Ep 279 | Reward: 5.84 | Steps: 81 | Captures: 1 | Caught: True\n",
      "Ep 280 | Reward: -2.97 | Steps: 36 | Captures: 0 | Caught: True\n",
      "Ep 281 | Reward: -3.41 | Steps: 63 | Captures: 0 | Caught: True\n",
      "Ep 282 | Reward: -0.63 | Steps: 44 | Captures: 0 | Caught: True\n",
      "Ep 283 | Reward: -4.85 | Steps: 73 | Captures: 0 | Caught: True\n",
      "Ep 284 | Reward: -5.81 | Steps: 66 | Captures: 0 | Caught: True\n",
      "Ep 285 | Reward: 7.16 | Steps: 94 | Captures: 1 | Caught: True\n",
      "Ep 286 | Reward: -2.05 | Steps: 55 | Captures: 0 | Caught: True\n",
      "Ep 287 | Reward: -3.58 | Steps: 50 | Captures: 0 | Caught: True\n",
      "Ep 288 | Reward: -2.56 | Steps: 24 | Captures: 0 | Caught: True\n",
      "Ep 289 | Reward: -5.79 | Steps: 69 | Captures: 0 | Caught: True\n",
      "Ep 290 | Reward: 4.31 | Steps: 142 | Captures: 1 | Caught: True\n",
      "Ep 291 | Reward: -4.19 | Steps: 60 | Captures: 0 | Caught: True\n",
      "Ep 292 | Reward: -5.76 | Steps: 60 | Captures: 0 | Caught: True\n",
      "Ep 293 | Reward: -3.69 | Steps: 67 | Captures: 0 | Caught: True\n",
      "Ep 294 | Reward: 5.77 | Steps: 57 | Captures: 1 | Caught: True\n",
      "Ep 295 | Reward: -2.25 | Steps: 278 | Captures: 1 | Caught: True\n",
      "Ep 296 | Reward: -4.72 | Steps: 49 | Captures: 0 | Caught: True\n",
      "Ep 297 | Reward: -11.04 | Steps: 157 | Captures: 0 | Caught: True\n",
      "Ep 298 | Reward: -1.32 | Steps: 25 | Captures: 0 | Caught: True\n",
      "Ep 299 | Reward: -6.54 | Steps: 57 | Captures: 0 | Caught: True\n",
      "Ep 300 | Reward: -6.74 | Steps: 51 | Captures: 0 | Caught: True\n",
      "Ep 301 | Reward: 5.34 | Steps: 73 | Captures: 1 | Caught: True\n",
      "Ep 302 | Reward: -8.07 | Steps: 66 | Captures: 0 | Caught: True\n",
      "Ep 303 | Reward: -7.45 | Steps: 63 | Captures: 0 | Caught: True\n",
      "Ep 304 | Reward: -11.35 | Steps: 165 | Captures: 0 | Caught: True\n",
      "Ep 305 | Reward: -6.65 | Steps: 240 | Captures: 0 | Caught: True\n",
      "Ep 306 | Reward: -4.71 | Steps: 49 | Captures: 0 | Caught: True\n",
      "Ep 307 | Reward: 3.06 | Steps: 149 | Captures: 1 | Caught: True\n",
      "Ep 308 | Reward: -9.65 | Steps: 214 | Captures: 0 | Caught: True\n",
      "Ep 309 | Reward: -6.32 | Steps: 66 | Captures: 0 | Caught: True\n",
      "Ep 310 | Reward: 8.15 | Steps: 53 | Captures: 1 | Caught: True\n",
      "Ep 311 | Reward: -2.94 | Steps: 21 | Captures: 0 | Caught: True\n",
      "Ep 312 | Reward: -2.70 | Steps: 12 | Captures: 0 | Caught: True\n",
      "Ep 313 | Reward: -6.57 | Steps: 150 | Captures: 0 | Caught: True\n",
      "Ep 314 | Reward: -8.42 | Steps: 121 | Captures: 0 | Caught: True\n",
      "Ep 315 | Reward: -9.73 | Steps: 236 | Captures: 0 | Caught: True\n",
      "Ep 316 | Reward: -5.30 | Steps: 57 | Captures: 0 | Caught: True\n",
      "Ep 317 | Reward: -2.71 | Steps: 14 | Captures: 0 | Caught: True\n",
      "Ep 318 | Reward: -5.56 | Steps: 97 | Captures: 0 | Caught: True\n",
      "Ep 319 | Reward: -4.15 | Steps: 358 | Captures: 1 | Caught: True\n",
      "Ep 320 | Reward: -6.92 | Steps: 60 | Captures: 0 | Caught: True\n",
      "Ep 321 | Reward: 0.23 | Steps: 500 | Captures: 1 | Caught: False\n",
      "Ep 322 | Reward: -10.60 | Steps: 160 | Captures: 0 | Caught: True\n",
      "Ep 323 | Reward: -6.72 | Steps: 57 | Captures: 0 | Caught: True\n",
      "Ep 324 | Reward: -5.50 | Steps: 97 | Captures: 0 | Caught: True\n",
      "Ep 325 | Reward: -2.80 | Steps: 21 | Captures: 0 | Caught: True\n",
      "Ep 326 | Reward: -3.04 | Steps: 500 | Captures: 0 | Caught: False\n",
      "Ep 327 | Reward: -8.31 | Steps: 86 | Captures: 0 | Caught: True\n",
      "Ep 328 | Reward: -10.58 | Steps: 185 | Captures: 0 | Caught: True\n",
      "Ep 329 | Reward: 4.14 | Steps: 99 | Captures: 1 | Caught: True\n",
      "Ep 330 | Reward: -8.21 | Steps: 239 | Captures: 0 | Caught: True\n",
      "Ep 331 | Reward: -5.84 | Steps: 68 | Captures: 0 | Caught: True\n",
      "Ep 332 | Reward: -12.71 | Steps: 203 | Captures: 0 | Caught: True\n",
      "Ep 333 | Reward: -10.75 | Steps: 281 | Captures: 0 | Caught: True\n",
      "Ep 334 | Reward: -5.08 | Steps: 144 | Captures: 0 | Caught: True\n",
      "Ep 335 | Reward: -12.33 | Steps: 500 | Captures: 0 | Caught: False\n",
      "Ep 336 | Reward: -5.26 | Steps: 68 | Captures: 0 | Caught: True\n",
      "Ep 337 | Reward: -2.77 | Steps: 14 | Captures: 0 | Caught: True\n",
      "Ep 338 | Reward: -5.75 | Steps: 50 | Captures: 0 | Caught: True\n",
      "Ep 339 | Reward: -4.71 | Steps: 72 | Captures: 0 | Caught: True\n",
      "Ep 340 | Reward: -7.83 | Steps: 68 | Captures: 0 | Caught: True\n",
      "Ep 341 | Reward: -5.00 | Steps: 54 | Captures: 0 | Caught: True\n",
      "Ep 342 | Reward: -11.06 | Steps: 89 | Captures: 0 | Caught: True\n",
      "Ep 343 | Reward: -12.63 | Steps: 461 | Captures: 0 | Caught: True\n",
      "Ep 344 | Reward: -5.78 | Steps: 49 | Captures: 0 | Caught: True\n",
      "Ep 345 | Reward: -6.12 | Steps: 59 | Captures: 0 | Caught: True\n",
      "Ep 346 | Reward: -2.81 | Steps: 55 | Captures: 0 | Caught: True\n",
      "Ep 347 | Reward: -5.66 | Steps: 74 | Captures: 0 | Caught: True\n",
      "Ep 348 | Reward: -6.28 | Steps: 269 | Captures: 1 | Caught: True\n",
      "Ep 349 | Reward: -7.20 | Steps: 199 | Captures: 0 | Caught: True\n",
      "Ep 350 | Reward: -5.81 | Steps: 74 | Captures: 0 | Caught: True\n",
      "Ep 351 | Reward: -6.50 | Steps: 90 | Captures: 0 | Caught: True\n",
      "Ep 352 | Reward: -10.16 | Steps: 148 | Captures: 0 | Caught: True\n",
      "Ep 353 | Reward: -6.88 | Steps: 117 | Captures: 0 | Caught: True\n",
      "Ep 354 | Reward: -5.81 | Steps: 126 | Captures: 0 | Caught: True\n",
      "Ep 355 | Reward: -2.76 | Steps: 10 | Captures: 0 | Caught: True\n",
      "Ep 356 | Reward: -9.57 | Steps: 142 | Captures: 0 | Caught: True\n",
      "Ep 357 | Reward: -0.01 | Steps: 195 | Captures: 1 | Caught: True\n",
      "Ep 358 | Reward: -2.68 | Steps: 21 | Captures: 0 | Caught: True\n",
      "Ep 359 | Reward: -3.14 | Steps: 72 | Captures: 0 | Caught: True\n",
      "Ep 360 | Reward: 13.21 | Steps: 116 | Captures: 2 | Caught: True\n",
      "Ep 361 | Reward: -5.89 | Steps: 127 | Captures: 0 | Caught: True\n",
      "Ep 362 | Reward: -5.52 | Steps: 53 | Captures: 0 | Caught: True\n",
      "Ep 363 | Reward: -2.76 | Steps: 53 | Captures: 0 | Caught: True\n",
      "Ep 364 | Reward: -8.35 | Steps: 244 | Captures: 0 | Caught: True\n",
      "Ep 365 | Reward: -7.17 | Steps: 59 | Captures: 0 | Caught: True\n",
      "Ep 366 | Reward: -4.44 | Steps: 40 | Captures: 0 | Caught: True\n",
      "Ep 367 | Reward: 2.62 | Steps: 306 | Captures: 1 | Caught: True\n",
      "Ep 368 | Reward: -2.74 | Steps: 175 | Captures: 0 | Caught: True\n",
      "Ep 369 | Reward: 6.39 | Steps: 184 | Captures: 1 | Caught: True\n",
      "Ep 370 | Reward: -8.45 | Steps: 64 | Captures: 0 | Caught: True\n",
      "Ep 371 | Reward: -6.65 | Steps: 76 | Captures: 0 | Caught: True\n",
      "Ep 372 | Reward: -2.68 | Steps: 14 | Captures: 0 | Caught: True\n",
      "Ep 373 | Reward: -10.29 | Steps: 112 | Captures: 0 | Caught: True\n",
      "Ep 374 | Reward: 50.18 | Steps: 500 | Captures: 5 | Caught: False\n",
      "Ep 375 | Reward: -7.94 | Steps: 500 | Captures: 0 | Caught: False\n",
      "Ep 376 | Reward: -2.70 | Steps: 23 | Captures: 0 | Caught: True\n",
      "Ep 377 | Reward: -9.64 | Steps: 116 | Captures: 0 | Caught: True\n",
      "Ep 378 | Reward: 5.97 | Steps: 108 | Captures: 1 | Caught: True\n",
      "Ep 379 | Reward: -2.80 | Steps: 36 | Captures: 0 | Caught: True\n",
      "Ep 380 | Reward: 3.17 | Steps: 500 | Captures: 1 | Caught: False\n",
      "Ep 381 | Reward: -12.89 | Steps: 186 | Captures: 0 | Caught: True\n",
      "Ep 382 | Reward: -3.87 | Steps: 55 | Captures: 0 | Caught: True\n",
      "Ep 383 | Reward: -5.82 | Steps: 184 | Captures: 0 | Caught: True\n",
      "Ep 384 | Reward: -7.49 | Steps: 74 | Captures: 0 | Caught: True\n",
      "Ep 385 | Reward: 11.20 | Steps: 500 | Captures: 1 | Caught: False\n",
      "Ep 386 | Reward: -2.84 | Steps: 24 | Captures: 0 | Caught: True\n",
      "Ep 387 | Reward: 4.60 | Steps: 500 | Captures: 2 | Caught: False\n",
      "Ep 388 | Reward: 4.36 | Steps: 116 | Captures: 1 | Caught: True\n",
      "Ep 389 | Reward: 0.85 | Steps: 198 | Captures: 1 | Caught: True\n",
      "Ep 390 | Reward: 0.52 | Steps: 500 | Captures: 1 | Caught: False\n",
      "Ep 391 | Reward: 5.44 | Steps: 78 | Captures: 1 | Caught: True\n",
      "Ep 392 | Reward: -5.98 | Steps: 72 | Captures: 0 | Caught: True\n",
      "Ep 393 | Reward: -5.95 | Steps: 62 | Captures: 0 | Caught: True\n",
      "Ep 394 | Reward: -5.90 | Steps: 63 | Captures: 0 | Caught: True\n",
      "Ep 395 | Reward: 8.38 | Steps: 31 | Captures: 1 | Caught: True\n",
      "Ep 396 | Reward: -6.54 | Steps: 50 | Captures: 0 | Caught: True\n",
      "Ep 397 | Reward: -2.64 | Steps: 18 | Captures: 0 | Caught: True\n",
      "Ep 398 | Reward: 16.13 | Steps: 238 | Captures: 2 | Caught: True\n",
      "Ep 399 | Reward: -3.10 | Steps: 64 | Captures: 0 | Caught: True\n",
      "Ep 400 | Reward: -8.53 | Steps: 340 | Captures: 0 | Caught: True\n",
      "Ep 401 | Reward: -1.74 | Steps: 27 | Captures: 0 | Caught: True\n",
      "Ep 402 | Reward: 8.44 | Steps: 47 | Captures: 1 | Caught: True\n",
      "Ep 403 | Reward: 5.55 | Steps: 273 | Captures: 1 | Caught: True\n",
      "Ep 404 | Reward: -1.92 | Steps: 44 | Captures: 0 | Caught: True\n",
      "Ep 405 | Reward: -14.16 | Steps: 457 | Captures: 0 | Caught: True\n",
      "Ep 406 | Reward: 6.83 | Steps: 104 | Captures: 1 | Caught: True\n",
      "Ep 407 | Reward: -6.12 | Steps: 164 | Captures: 0 | Caught: True\n",
      "Ep 408 | Reward: -4.47 | Steps: 36 | Captures: 0 | Caught: True\n",
      "Ep 409 | Reward: 16.60 | Steps: 176 | Captures: 2 | Caught: True\n",
      "Ep 410 | Reward: -1.59 | Steps: 177 | Captures: 1 | Caught: True\n",
      "Ep 411 | Reward: -4.78 | Steps: 59 | Captures: 0 | Caught: True\n",
      "Ep 412 | Reward: 4.37 | Steps: 500 | Captures: 0 | Caught: False\n",
      "Ep 413 | Reward: -6.53 | Steps: 156 | Captures: 0 | Caught: True\n",
      "Ep 414 | Reward: -4.43 | Steps: 500 | Captures: 0 | Caught: False\n",
      "Ep 415 | Reward: -1.79 | Steps: 33 | Captures: 0 | Caught: True\n",
      "Ep 416 | Reward: -6.30 | Steps: 52 | Captures: 0 | Caught: True\n",
      "Ep 417 | Reward: -15.73 | Steps: 460 | Captures: 0 | Caught: True\n",
      "Ep 418 | Reward: -6.56 | Steps: 45 | Captures: 0 | Caught: True\n",
      "Ep 419 | Reward: -6.42 | Steps: 53 | Captures: 0 | Caught: True\n",
      "Ep 420 | Reward: 8.35 | Steps: 86 | Captures: 1 | Caught: True\n",
      "Ep 421 | Reward: -8.05 | Steps: 75 | Captures: 0 | Caught: True\n",
      "Ep 422 | Reward: 9.23 | Steps: 102 | Captures: 1 | Caught: True\n",
      "Ep 423 | Reward: -6.30 | Steps: 45 | Captures: 0 | Caught: True\n",
      "Ep 424 | Reward: 7.67 | Steps: 492 | Captures: 2 | Caught: True\n",
      "Ep 425 | Reward: -4.83 | Steps: 369 | Captures: 1 | Caught: True\n",
      "Ep 426 | Reward: -6.86 | Steps: 69 | Captures: 0 | Caught: True\n",
      "Ep 427 | Reward: 3.22 | Steps: 500 | Captures: 1 | Caught: False\n",
      "Ep 428 | Reward: -2.79 | Steps: 14 | Captures: 0 | Caught: True\n",
      "Ep 429 | Reward: 4.55 | Steps: 167 | Captures: 1 | Caught: True\n",
      "Ep 430 | Reward: -4.87 | Steps: 82 | Captures: 0 | Caught: True\n",
      "Ep 431 | Reward: 8.73 | Steps: 407 | Captures: 1 | Caught: True\n",
      "Ep 432 | Reward: -4.63 | Steps: 500 | Captures: 0 | Caught: False\n",
      "Ep 433 | Reward: -3.18 | Steps: 113 | Captures: 0 | Caught: True\n",
      "Ep 434 | Reward: 5.98 | Steps: 500 | Captures: 1 | Caught: False\n",
      "Ep 435 | Reward: 10.87 | Steps: 500 | Captures: 1 | Caught: False\n",
      "Ep 436 | Reward: 17.10 | Steps: 189 | Captures: 2 | Caught: True\n",
      "Ep 437 | Reward: 8.18 | Steps: 44 | Captures: 1 | Caught: True\n",
      "Ep 438 | Reward: -7.59 | Steps: 73 | Captures: 0 | Caught: True\n",
      "Ep 439 | Reward: -3.14 | Steps: 20 | Captures: 0 | Caught: True\n",
      "Ep 440 | Reward: -3.10 | Steps: 216 | Captures: 0 | Caught: True\n",
      "Ep 441 | Reward: -1.49 | Steps: 142 | Captures: 0 | Caught: True\n",
      "Ep 442 | Reward: 13.79 | Steps: 204 | Captures: 2 | Caught: True\n",
      "Ep 443 | Reward: -8.59 | Steps: 186 | Captures: 0 | Caught: True\n",
      "Ep 444 | Reward: -2.68 | Steps: 81 | Captures: 0 | Caught: True\n",
      "Ep 445 | Reward: -6.86 | Steps: 54 | Captures: 0 | Caught: True\n",
      "Ep 446 | Reward: -3.96 | Steps: 96 | Captures: 0 | Caught: True\n",
      "Ep 447 | Reward: -0.93 | Steps: 56 | Captures: 0 | Caught: True\n",
      "Ep 448 | Reward: -1.32 | Steps: 118 | Captures: 0 | Caught: True\n",
      "Ep 449 | Reward: 34.59 | Steps: 500 | Captures: 4 | Caught: False\n",
      "Ep 450 | Reward: -5.80 | Steps: 125 | Captures: 0 | Caught: True\n",
      "Ep 451 | Reward: 21.17 | Steps: 170 | Captures: 2 | Caught: True\n",
      "Ep 452 | Reward: 4.60 | Steps: 225 | Captures: 1 | Caught: True\n",
      "Ep 453 | Reward: -2.78 | Steps: 24 | Captures: 0 | Caught: True\n",
      "Ep 454 | Reward: -6.42 | Steps: 48 | Captures: 0 | Caught: True\n",
      "Ep 455 | Reward: -3.96 | Steps: 325 | Captures: 0 | Caught: True\n",
      "Ep 456 | Reward: 7.00 | Steps: 183 | Captures: 1 | Caught: True\n",
      "Ep 457 | Reward: -7.09 | Steps: 61 | Captures: 0 | Caught: True\n",
      "Ep 458 | Reward: 3.49 | Steps: 224 | Captures: 1 | Caught: True\n",
      "Ep 459 | Reward: -4.79 | Steps: 120 | Captures: 0 | Caught: True\n",
      "Ep 460 | Reward: -6.02 | Steps: 57 | Captures: 0 | Caught: True\n",
      "Ep 461 | Reward: 48.92 | Steps: 477 | Captures: 5 | Caught: True\n",
      "Ep 462 | Reward: -3.85 | Steps: 64 | Captures: 0 | Caught: True\n",
      "Ep 463 | Reward: -6.43 | Steps: 63 | Captures: 0 | Caught: True\n",
      "Ep 464 | Reward: 39.45 | Steps: 482 | Captures: 4 | Caught: True\n",
      "Ep 465 | Reward: -6.61 | Steps: 62 | Captures: 0 | Caught: True\n",
      "Ep 466 | Reward: -7.97 | Steps: 59 | Captures: 0 | Caught: True\n",
      "Ep 467 | Reward: -3.69 | Steps: 132 | Captures: 0 | Caught: True\n",
      "Ep 468 | Reward: 15.25 | Steps: 253 | Captures: 2 | Caught: True\n",
      "Ep 469 | Reward: 9.22 | Steps: 371 | Captures: 1 | Caught: True\n",
      "Ep 470 | Reward: -6.69 | Steps: 144 | Captures: 0 | Caught: True\n",
      "Ep 471 | Reward: -6.25 | Steps: 106 | Captures: 0 | Caught: True\n",
      "Ep 472 | Reward: -2.87 | Steps: 45 | Captures: 0 | Caught: True\n",
      "Ep 473 | Reward: 10.99 | Steps: 500 | Captures: 1 | Caught: False\n",
      "Ep 474 | Reward: -8.19 | Steps: 74 | Captures: 0 | Caught: True\n",
      "Ep 475 | Reward: -1.90 | Steps: 78 | Captures: 0 | Caught: True\n",
      "Ep 476 | Reward: 30.91 | Steps: 500 | Captures: 3 | Caught: False\n",
      "Ep 477 | Reward: 75.76 | Steps: 500 | Captures: 7 | Caught: False\n",
      "Ep 478 | Reward: -5.03 | Steps: 37 | Captures: 0 | Caught: True\n",
      "Ep 479 | Reward: -2.37 | Steps: 24 | Captures: 0 | Caught: True\n",
      "Ep 480 | Reward: -5.13 | Steps: 500 | Captures: 0 | Caught: False\n",
      "Ep 481 | Reward: 4.30 | Steps: 424 | Captures: 1 | Caught: True\n",
      "Ep 482 | Reward: -1.06 | Steps: 56 | Captures: 0 | Caught: True\n",
      "Ep 483 | Reward: -5.04 | Steps: 55 | Captures: 0 | Caught: True\n",
      "Ep 484 | Reward: 7.20 | Steps: 83 | Captures: 1 | Caught: True\n",
      "Ep 485 | Reward: -6.16 | Steps: 61 | Captures: 0 | Caught: True\n",
      "Ep 486 | Reward: -4.15 | Steps: 92 | Captures: 0 | Caught: True\n",
      "Ep 487 | Reward: -4.84 | Steps: 106 | Captures: 0 | Caught: True\n",
      "Ep 488 | Reward: -7.82 | Steps: 57 | Captures: 0 | Caught: True\n",
      "Ep 489 | Reward: -19.22 | Steps: 500 | Captures: 0 | Caught: False\n",
      "Ep 490 | Reward: -3.28 | Steps: 281 | Captures: 0 | Caught: True\n",
      "Ep 491 | Reward: -7.61 | Steps: 88 | Captures: 0 | Caught: True\n",
      "Ep 492 | Reward: 7.68 | Steps: 500 | Captures: 1 | Caught: False\n",
      "Ep 493 | Reward: 35.54 | Steps: 296 | Captures: 3 | Caught: True\n",
      "Ep 494 | Reward: -2.78 | Steps: 56 | Captures: 0 | Caught: True\n",
      "Ep 495 | Reward: -2.88 | Steps: 71 | Captures: 0 | Caught: True\n",
      "Ep 496 | Reward: 11.30 | Steps: 175 | Captures: 1 | Caught: True\n",
      "Ep 497 | Reward: -4.49 | Steps: 114 | Captures: 0 | Caught: True\n",
      "Ep 498 | Reward: 1.74 | Steps: 475 | Captures: 1 | Caught: True\n",
      "Ep 499 | Reward: -1.86 | Steps: 424 | Captures: 0 | Caught: True\n",
      "Total reward in evaluation: -2.79\n"
     ]
    }
   ],
   "source": [
    "# TODO: Train and evaluate CatMouseEnv\n",
    "def select_action(state, model, epsilon, action_space):\n",
    "    if random.random() < epsilon:\n",
    "        return [random.randint(0, 2), random.randint(0, 2)]\n",
    "    with torch.no_grad():\n",
    "        state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "        q_values = model(state_tensor)\n",
    "        action = q_values.argmax(dim=1).item()\n",
    "        return [action // 3, action % 3]  # Convert flat index to (x,y) action\n",
    "\n",
    "env = ChaseEscapeEnv()\n",
    "dqn = DQN(state_space=8, action_space=9)  # 3x3 = 9 actions\n",
    "target_dqn = DQN(8, 9)\n",
    "target_dqn.load_state_dict(dqn.state_dict())\n",
    "optimizer = torch.optim.Adam(dqn.parameters(), lr=1e-3)\n",
    "buffer = ExperienceBuffer(capacity=10000)\n",
    "\n",
    "gamma = 0.99\n",
    "batch_size = 64\n",
    "epsilon = 1.0\n",
    "min_epsilon = 0.05\n",
    "epsilon_decay = 0.995\n",
    "max_steps = 500\n",
    "\n",
    "for episode in range(500):\n",
    "    state, _ = env.reset()\n",
    "    total_reward = 0\n",
    "    steps = 0\n",
    "    done = False\n",
    "    steps = 0\n",
    "    target_captures = 0\n",
    "    caught_by_chaser = False\n",
    "\n",
    "    while not done and steps < max_steps:\n",
    "        steps += 1\n",
    "        action = select_action(state, dqn, epsilon, env.action_space)\n",
    "        flat_action = action[0] * 3 + action[1]\n",
    "        next_state, reward, terminated, truncated, info = env.step(action)\n",
    "        buffer.push(state, flat_action, reward, next_state, terminated)\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "        done = terminated\n",
    "\n",
    "        # Track extra info\n",
    "        if info.get(\"target_captured\"):\n",
    "            target_captures += 1\n",
    "        if info.get(\"caught_by_chaser\"):\n",
    "            caught_by_chaser = True\n",
    "\n",
    "        # Train if enough samples\n",
    "        if len(buffer) > batch_size:\n",
    "            states, actions, rewards, next_states, dones = buffer.sample(batch_size)\n",
    "            states = torch.FloatTensor(states)\n",
    "            actions = torch.LongTensor(actions)\n",
    "            rewards = torch.FloatTensor(rewards)\n",
    "            next_states = torch.FloatTensor(next_states)\n",
    "            dones = torch.FloatTensor(dones)\n",
    "\n",
    "            q_values = dqn(states)\n",
    "            next_q_values = target_dqn(next_states)\n",
    "\n",
    "            q_target = rewards + gamma * next_q_values.max(1)[0] * (1 - dones)\n",
    "            q_expected = q_values.gather(1, actions.unsqueeze(1)).squeeze(1)\n",
    "\n",
    "            loss = F.mse_loss(q_expected, q_target)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    if epsilon > min_epsilon:\n",
    "        epsilon *= epsilon_decay\n",
    "\n",
    "    if episode % 10 == 0:\n",
    "        target_dqn.load_state_dict(dqn.state_dict())\n",
    "\n",
    "    # â Clean, compact log per episode\n",
    "    print(\n",
    "        f\"Ep {episode:03d} | \"\n",
    "        f\"Reward: {total_reward:.2f} | \"\n",
    "        f\"Steps: {steps} | \"\n",
    "        f\"Captures: {target_captures} | \"\n",
    "        f\"Caught: {caught_by_chaser}\"\n",
    "    )\n",
    "\n",
    "# Evaluation phase\n",
    "state, _ = env.reset()\n",
    "done = False\n",
    "total_reward = 0\n",
    "while not done:\n",
    "    env.render()\n",
    "    action = select_action(state, dqn, epsilon=0.0, action_space=env.action_space)\n",
    "    state, reward, terminated, _, _ = env.step(action)\n",
    "    total_reward += reward\n",
    "    done = terminated\n",
    "    pygame.time.delay(50)\n",
    "\n",
    "print(f\"Total reward in evaluation: {total_reward:.2f}\")\n",
    "env.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 BotB (venv)",
   "language": "python",
   "name": "venv310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
